{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"TP_AP_Kaggle.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"smWWYPCfvlKQ","colab_type":"text"},"source":["# Procesamiento de datos usando Tensorflow\n","\n","Cuando trabajamos con Tensorflow, existen una gran variedad de formas en las que podemos alimentar los datos a nuestra red neuronal. Esto también tiene que ver con el tipo de datos y los pasos de pre-procesamiento que sean necesarios.\n","\n","En la notebook 1 se utilizó un conjunto de datos de imágenes, esencialmente con variables numéricas. En esta notebook trabajemos con datos categóricos y profundizaremos en cómo trasformar los ejemplos dentro del pipeline de clasificación.\n","\n","Ante un problema de clasificación, lo primero que debemos hacer es **inspeccionar los datos y construir un prototipo de modelo**. La forma más fácil de hacerlo es con notebooks. Sin embargo, a la hora de llevar a cabo experimentos con redes neuronales, un entorno interactivo puede no ser la mejor opción. En primer lugar, explorar los hiperparámetros de una arquitectura neuronal puede llevar varias horas e incluso días, perdiendo todas las ventajas del entorno interactivo. En segundo lugar, no podemos encolar ejecuciones de notebooks para reservar recursos como las GPUs.\n","\n","Por ello, primero realizaremos una exploración inicial de los datos en esta notebook. Una vez que decidamos qué tipo de modelo implementar, pasaremos el modelo a un script de python que cargue los datos, construya el modelo, lo entrene, y finalmente guarde las métricas relevantes.\n","\n","En esta notebook, veremos varios conceptos avanzados de entrenamiento de redes:\n","\n","  * Uso de `tf.data.Dataset` para optimizar la ingesta de datos. \n","  * Uso de capas `tf.layers.Embedding`.\n","  * Combinación de distintos tipos de features en un mismo modelo con múltiples inputs.\n","  * MLFlow para registro de experimentos"]},{"cell_type":"code","metadata":{"id":"mOEuTzXavlKR","colab_type":"code","colab":{}},"source":["import os\n","import numpy\n","import pandas\n","import seaborn\n","seaborn.set_style('whitegrid')\n","seaborn.set_palette('colorblind')\n","seaborn.set_context('paper')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wber41hTvlKW","colab_type":"text"},"source":["## Cargando los datos\n","\n","Una vez más, estaremos trabajando con el conjunto de datos `petfinder`. Deben descargarlo siguiendo las instrucciones en la [notebook 0](./0_set_up.ipynb), descomprimirlo y luego ajustar la dirección en esta notebook según corresponda. \n","\n","Algunas de las preguntas que respondemos durante esta etapa son:\n","\n"," * ¿Qué tipo de tarea tengo que resolver? ¿Clasificación o regresión?\n"," * ¿Qué distribución tienen mis etiquetas?\n"," * ¿Qué tipo de datos tengo disponible para la clasificación? ¿Cuáles son útiles?\n"," * Dadas las características disponibles y el problema que quiero resolver, ¿qué tipo de clasificador o arquitectura conviene utilizar? ¿De qué manera se están representando las causas latentes del problema en el modelo elegido?\n"," * Dadas las características disponibles y el modelo elegido, ¿de qué forma representaremos cada una de dichas características?\n"," \n","En esta clase utilizaremos redes neuronales como modelos porque es el objetivo de la materia, pero sigue siendo importante qué aspectos podremos capturar con este tipo de modelo, especialmente para tener intuiciones sobre qué hiperparámetros explorar."]},{"cell_type":"code","metadata":{"id":"FL-Bog54vlKX","colab_type":"code","colab":{}},"source":["DATA_DIRECTORY = '../petfinder_dataset/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhJ8rj-nJmE5","colab_type":"code","outputId":"907b25df-9eba-4608-fa8d-eecd8af9ef32","executionInfo":{"status":"ok","timestamp":1571230929225,"user_tz":180,"elapsed":71930,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74}},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-ad10fcf2-b128-4dc5-9fef-1e3d0128163a\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-ad10fcf2-b128-4dc5-9fef-1e3d0128163a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving train.csv to train.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k59DeTMaKHxg","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","import io\n","\n","dataset, dev_dataset = train_test_split(\n","    pandas.read_csv(io.BytesIO(uploaded['train.csv'])), test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"chRUDOp9vlKa","colab_type":"code","colab":{}},"source":["# Take a sample of data\n","\n","from sklearn.model_selection import train_test_split\n","\n","dataset, dev_dataset = train_test_split(\n","    pandas.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv')), test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVT-iNgJvlKd","colab_type":"code","outputId":"04285284-9f4b-4a49-822d-b7a5583f2f23","executionInfo":{"status":"ok","timestamp":1571230935972,"user_tz":180,"elapsed":1082,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["dataset[:3]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>Age</th>\n","      <th>Breed1</th>\n","      <th>Breed2</th>\n","      <th>Gender</th>\n","      <th>Color1</th>\n","      <th>Color2</th>\n","      <th>Color3</th>\n","      <th>MaturitySize</th>\n","      <th>FurLength</th>\n","      <th>Vaccinated</th>\n","      <th>Dewormed</th>\n","      <th>Sterilized</th>\n","      <th>Health</th>\n","      <th>Quantity</th>\n","      <th>Fee</th>\n","      <th>State</th>\n","      <th>Description</th>\n","      <th>AdoptionSpeed</th>\n","      <th>PID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5301</th>\n","      <td>2</td>\n","      <td>36</td>\n","      <td>266</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>41326</td>\n","      <td>Lovely former alley cat. Rescued and spayed by...</td>\n","      <td>1</td>\n","      <td>7485</td>\n","    </tr>\n","    <tr>\n","      <th>6172</th>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>39</td>\n","      <td>307</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>41326</td>\n","      <td>Female dog found wandering in Bandar Kinrara 4...</td>\n","      <td>3</td>\n","      <td>8686</td>\n","    </tr>\n","    <tr>\n","      <th>255</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>264</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>41326</td>\n","      <td>We found 2 lovely male kittens at the roadside...</td>\n","      <td>4</td>\n","      <td>359</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Type  Age  ...  AdoptionSpeed   PID\n","5301     2   36  ...              1  7485\n","6172     1   12  ...              3  8686\n","255      2    1  ...              4   359\n","\n","[3 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"pgWs4orUvlKi","colab_type":"text"},"source":["### Tipos de datos"]},{"cell_type":"code","metadata":{"id":"D3oQZ-vkvlKj","colab_type":"code","outputId":"3e97f6e9-2703-4299-8c01-46953a40c4af","executionInfo":{"status":"ok","timestamp":1570998608211,"user_tz":180,"elapsed":735,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["dataset.dtypes"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Type              int64\n","Age               int64\n","Breed1            int64\n","Breed2            int64\n","Gender            int64\n","Color1            int64\n","Color2            int64\n","Color3            int64\n","MaturitySize      int64\n","FurLength         int64\n","Vaccinated        int64\n","Dewormed          int64\n","Sterilized        int64\n","Health            int64\n","Quantity          int64\n","Fee               int64\n","State             int64\n","Description      object\n","AdoptionSpeed     int64\n","PID               int64\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"4F5Dj2N3vlKm","colab_type":"code","colab":{}},"source":["target_col = 'AdoptionSpeed'\n","nlabels = dataset[target_col].unique().shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gGIedATIvlKp","colab_type":"text"},"source":["### Distribución de las etiquetas"]},{"cell_type":"code","metadata":{"id":"33KnfHCnvlKq","colab_type":"code","outputId":"9cd0e3ad-56bd-440d-9317-ba713ae2c2fa","executionInfo":{"status":"ok","timestamp":1570998618229,"user_tz":180,"elapsed":987,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":284}},"source":["seaborn.countplot(dataset.AdoptionSpeed, color='blue')\n","seaborn.despine()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"BkktvL3pvlKt","colab_type":"text"},"source":["https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n","\n","https://www.tensorflow.org/tutorials/structured_data/feature_columns\n","\n","Why not to use feature_columns https://github.com/tensorflow/tensorflow/issues/27895\n","\n","feature_columns doc 2.0 https://www.tensorflow.org/api_docs/python/tf/feature_column"]},{"cell_type":"code","metadata":{"id":"5UL7q8qBvlKu","colab_type":"code","outputId":"e0f2ccd3-8852-4b79-c0ae-2fbb10c876e1","executionInfo":{"status":"ok","timestamp":1571230946117,"user_tz":180,"elapsed":4459,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["try:\n","    # %tensorflow_version only exists in Colab.\n","    %tensorflow_version 2.x\n","except Exception:\n","    pass\n","import tensorflow as tf\n","\n","from tensorflow.keras import layers, models"],"execution_count":7,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AIgZD1DFvlKx","colab_type":"text"},"source":["## Creando las representaciones"]},{"cell_type":"markdown","metadata":{"id":"WN3VhnnSvlKy","colab_type":"text"},"source":["Tenemos una serie de variables categóricas y ordinales que pueden ser útiles para predecir la velocidad de adopción. Para cada una de ellas, tenemos que pensar cuál es la mejor forma de pasarla como input a la red. Analizaremos algunas de ellas:\n","\n","  * `Age` es una variable numérica discreta, podemos representarla con una única neurona con el valor original. Es muy importante normalizar este tipo de variables.\n","  * `Gender` es una variable categórica. Como la variable tiene pocos valores, utilizaremos un *one-hot encoding* como representación.\n","  * `Breed1` es una variable categórica que puede tomar muchos valores. Podemos utilizar *one-hot encoding*, lo cual resultará en vectores esparsos de dimensión cercana a 300. Alternativamente, podemos utilizar una capa de embedding para representar sus valores con un vector denso de baja dimesionalidad. Pregunta: ¿qué información podrá capturar este embedding?"]},{"cell_type":"markdown","metadata":{"id":"FhP4kIfJvlKz","colab_type":"text"},"source":["Una vez que definimos cómo vamos a representar cada una de las columnas, las pre-procesamos para formar un numpy array. En este caso, procesaremos el dataset completo porque estamos seguros de que entrará en memoria. En otros casos, puede ser necesario un pre-procesamiento por batches, o incluso utilizar las funciones de Tensorflow incluidas en el módulo `feature_column`.\n","\n","NOTA: para este ejercicio, intentamos utilizar `feature_column` pero causaba que la loss diverga. La documentación no ha sido totalmente actualizada a Tensorflow 2.0, y puede ser que nos encontremos ante un error de cambio de versiones. Pueden encontrar más ejemplos en [este link](https://www.tensorflow.org/tutorials/structured_data/feature_columns)."]},{"cell_type":"code","metadata":{"id":"06-xKpVa4aa0","colab_type":"code","outputId":"8ec10148-bbbb-4ccf-e5c7-c2fc3d436d7f","executionInfo":{"status":"ok","timestamp":1571230949616,"user_tz":180,"elapsed":1134,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["dataset.columns"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n","       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n","       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'Description',\n","       'AdoptionSpeed', 'PID'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"TN300Nh2vlK0","colab_type":"code","colab":{}},"source":["# It's important to always use the same one-hot length\n","one_hot_columns = {\n","    one_hot_col: dataset[one_hot_col].max()\n","    for one_hot_col in ['Type', 'Gender', 'MaturitySize', 'FurLength', \n","                        'Vaccinated', 'Dewormed', 'Sterilized', 'Health']\n","}\n","embedded_columns = {\n","    embedded_col: dataset[embedded_col].max() + 1\n","    for embedded_col in ['Breed1', 'Breed2', 'Color1', 'Color2',\n","       'Color3', 'State']\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJpvbh7wsHrq","colab_type":"code","colab":{}},"source":["from tensorflow import feature_column\n","\n","def process_features(df): \n","\n","  direct_features = []\n","  # Create one hot encodings\n","  for one_hot_col, max_value in one_hot_columns.items():\n","      direct_features.append(tf.keras.utils.to_categorical(df[one_hot_col] - 1, max_value))\n","  \n","  # Create and append numeric columns\n","  # Don't forget to normalize!\n","  # ....\n","  # numeric cols\n","  #numeric_features = {}\n","  #num_features = ['Age', 'Quantity', 'Fee'] \n","  #for header in num_features:\n","      #direct_features.append(feature_column.numeric_column(header))\n","  #for n_col in numeric_columns:\n","  #  numeric_features.append(tf.keras.utils.normalize(df[n_col].values))\n","  \n","  # Concatenate all features that don't need further embedding into a single matrix.\n","  features = {'direct_features':numpy.hstack(direct_features)}\n","  \n","  # Create embedding columns - nothing to do here. We will use the zero embedding for OOV\n","  for embedded_col in embedded_columns.keys():\n","      features[embedded_col] = df[embedded_col].values\n","  \n","  # Agrego\n","  for n_col in ['Age', 'Quantity', 'Fee']:\n","    features[n_col] = numpy.hstack(tf.keras.utils.normalize(df[n_col].values)) \n","  \n","  # Convert labels to one-hot encodings\n","  targets = tf.keras.utils.to_categorical(df[target_col], nlabels)\n","  \n","  return features, targets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8dxIlBfvlK5","colab_type":"code","colab":{}},"source":["X_train, y_train = process_features(dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HuKKOF4wvlK8","colab_type":"code","outputId":"7997fec8-53f1-49d3-a045-c608c90ae535","executionInfo":{"status":"ok","timestamp":1571230961236,"user_tz":180,"elapsed":1126,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["X_train"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Age': array([0.01848573, 0.00616191, 0.00051349, ..., 0.04313337, 0.01232382,\n","        0.00564842]),\n"," 'Breed1': array([266,  39, 264, ..., 179, 292, 307]),\n"," 'Breed2': array([  0, 307,   0, ...,   0,   0,   0]),\n"," 'Color1': array([7, 1, 1, ..., 1, 2, 2]),\n"," 'Color2': array([0, 7, 3, ..., 0, 5, 7]),\n"," 'Color3': array([0, 0, 0, ..., 0, 0, 0]),\n"," 'Fee': array([0.00668043, 0.        , 0.        , ..., 0.        , 0.02004128,\n","        0.        ]),\n"," 'Quantity': array([0.00510983, 0.00510983, 0.01021966, ..., 0.00510983, 0.00510983,\n","        0.00510983]),\n"," 'State': array([41326, 41326, 41326, ..., 41326, 41336, 41326]),\n"," 'direct_features': array([[0., 1., 0., ..., 1., 0., 0.],\n","        [1., 0., 0., ..., 1., 0., 0.],\n","        [0., 1., 0., ..., 1., 0., 0.],\n","        ...,\n","        [1., 0., 1., ..., 1., 0., 0.],\n","        [0., 1., 1., ..., 1., 0., 0.],\n","        [1., 0., 1., ..., 1., 0., 0.]], dtype=float32)}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"mGltIB_DvlK_","colab_type":"code","outputId":"5830e54a-2803-40ae-d12d-439adb4b3581","executionInfo":{"status":"ok","timestamp":1571230963858,"user_tz":180,"elapsed":1095,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["direct_features_input_shape = (X_train['direct_features'].shape[1])\n","direct_features_input_shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"GfWLruWMvlLD","colab_type":"text"},"source":["## Creando datasets iterables\n","\n","Como hemos visto, las redes neuronales se entrenan iterativamente con el algoritmo de *stochastic gradient descent*. Una forma de hacerlo es pasarle el dataset entero al método `fit` de un modelo de Keras, como vimos en la notebook anterior. Sin embargo, esto tiene algunas desventajas:\n","\n","* El dataset procesado debe entrar en memoria\n","* El dataset procesado debe entrar en disco, lo cual no siempre es factible para encodings y datasets realmente grandes (ej: la wikipedia)\n","* Una vez que la GPU ha terminado de procesar los datos, devuelve el control a la CPU (que estaba esperando sin hacer nada), y espera a que los nuevos datos son particionados.\n","* No es posible usar cálculo distribuido en distintos file systems.\n","\n","Las dos primeras desventajas se solucionan preprocesando los datos en batches, y creando matrices anchas pero con pocas filas. Sin embargo, escribir este código manualmente puede ser complejo y en general lo hacemos de manera ineficiente. Solucionar las dos últimas es bastante más complicado y a la vez crítico. \n","\n","> **No importa qué tan buen hardware usemos para el entrenamiento del modelo, si seguimos limitados por un procesamiento de datos lineal y single core.**\n","\n","Por eso es recomendable utilizar las abstracciones nativas provistas por Tensorflow que paralelizan internamente muchas funciones.\n","\n","Para ello, crearemos un objeto `tf.data.Dataset` iterable a partir de nuestro dataframe de pandas y no tendremos que preocuparnos por la optimización de la GPU. Los datasets saben cómo crear batches, shuffles, aplicar funciones map y filter, etc. Además, podemos crear datasets a partir de diversas estructuras de datos, como numpy arrays o archivos. Pueden encontrar más información sobre los distintos tipos de Datasets en [este tutorial](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428)"]},{"cell_type":"code","metadata":{"id":"DNIvv0UyvlLE","colab_type":"code","colab":{}},"source":["batch_size = 32\n","# TODO shuffle the train dataset!\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n","train_ds.shuffle(buffer_size=len(X_train))\n","\n","test_ds = tf.data.Dataset.from_tensor_slices(\n","    process_features(dev_dataset)).batch(batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eic8JXtZvlLH","colab_type":"text"},"source":["Podemos ver qué es lo que tiene adentro en dataset obteniendo la primera operación."]},{"cell_type":"code","metadata":{"id":"-qX4WM3pvlLI","colab_type":"code","outputId":"15136606-688b-42e1-e67b-f4c4adc5e605","executionInfo":{"status":"ok","timestamp":1571230972795,"user_tz":180,"elapsed":1109,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#tf.enable_eager_execution()\n","\n","x_batch, y_batch = next(iter(train_ds))\n","x_batch, y_batch"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'Age': <tf.Tensor: id=42, shape=(32,), dtype=float64, numpy=\n","  array([0.01848573, 0.00616191, 0.00051349, 0.00256746, 0.00102698,\n","         0.00154048, 0.00102698, 0.00462143, 0.00154048, 0.00102698,\n","         0.00308095, 0.00051349, 0.00205397, 0.00102698, 0.00102698,\n","         0.06161909, 0.00102698, 0.0138643 , 0.01540477, 0.00102698,\n","         0.00154048, 0.00205397, 0.00051349, 0.00308095, 0.01848573,\n","         0.00616191, 0.03080955, 0.00051349, 0.067781  , 0.09242864,\n","         0.00308095, 0.01026985])>,\n","  'Breed1': <tf.Tensor: id=43, shape=(32,), dtype=int64, numpy=\n","  array([266,  39, 264, 265, 266, 266, 307, 307, 103, 266, 266, 266, 266,\n","         266, 307, 103, 265, 265, 307, 307, 307, 266, 307, 266, 307, 285,\n","         205, 307, 195, 265, 205, 266])>,\n","  'Breed2': <tf.Tensor: id=44, shape=(32,), dtype=int64, numpy=\n","  array([  0, 307,   0,   0,   0,   0, 307,   0, 307,   0,   0,   0,   0,\n","           0, 103,   0, 265,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","           0,   0,   0,   0,   0, 292])>,\n","  'Color1': <tf.Tensor: id=45, shape=(32,), dtype=int64, numpy=\n","  array([7, 1, 1, 5, 2, 3, 1, 2, 2, 4, 1, 2, 2, 3, 1, 1, 1, 5, 1, 1, 2, 6,\n","         2, 1, 1, 1, 2, 1, 1, 1, 6, 2])>,\n","  'Color2': <tf.Tensor: id=46, shape=(32,), dtype=int64, numpy=\n","  array([0, 7, 3, 6, 3, 0, 2, 7, 0, 5, 0, 5, 7, 5, 2, 2, 2, 0, 5, 0, 0, 0,\n","         3, 6, 2, 2, 5, 7, 0, 7, 7, 5])>,\n","  'Color3': <tf.Tensor: id=47, shape=(32,), dtype=int64, numpy=\n","  array([0, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0,\n","         0, 7, 7, 3, 7, 0, 0, 0, 0, 7])>,\n","  'Fee': <tf.Tensor: id=48, shape=(32,), dtype=float64, numpy=\n","  array([0.00668043, 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.0267217 , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.00668043, 0.        , 0.        , 0.        ,\n","         0.        , 0.04008256, 0.        , 0.        , 0.        ,\n","         0.        , 0.00400826])>,\n","  'Quantity': <tf.Tensor: id=49, shape=(32,), dtype=float64, numpy=\n","  array([0.00510983, 0.00510983, 0.01021966, 0.01021966, 0.00510983,\n","         0.00510983, 0.00510983, 0.00510983, 0.00510983, 0.01021966,\n","         0.00510983, 0.00510983, 0.00510983, 0.00510983, 0.00510983,\n","         0.00510983, 0.01021966, 0.00510983, 0.00510983, 0.00510983,\n","         0.00510983, 0.00510983, 0.00510983, 0.00510983, 0.00510983,\n","         0.00510983, 0.00510983, 0.00510983, 0.00510983, 0.00510983,\n","         0.01021966, 0.00510983])>,\n","  'State': <tf.Tensor: id=50, shape=(32,), dtype=int64, numpy=\n","  array([41326, 41326, 41326, 41401, 41326, 41336, 41401, 41326, 41401,\n","         41401, 41401, 41326, 41401, 41401, 41326, 41326, 41326, 41332,\n","         41326, 41401, 41326, 41326, 41326, 41326, 41401, 41332, 41401,\n","         41327, 41327, 41326, 41327, 41326])>,\n","  'direct_features': <tf.Tensor: id=51, shape=(32, 24), dtype=float32, numpy=\n","  array([[0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n","          0., 0., 1., 0., 0., 1., 0., 0.],\n","         [1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n","          0., 0., 1., 0., 0., 1., 0., 0.],\n","         [0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n","          0., 0., 0., 1., 0., 0., 1., 0.],\n","         [1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n","          0., 0., 0., 0., 1., 1., 0., 0.],\n","         [1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n","          0., 0., 0., 1., 0., 1., 0., 0.],\n","         [1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n","          0., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n","          0., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n","          0., 0., 0., 1., 0., 1., 0., 0.],\n","         [1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n","          0., 0., 0., 1., 0., 1., 0., 0.],\n","         [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n","          0., 1., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n","          1., 0., 0., 0., 1., 1., 0., 0.],\n","         [1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n","          0., 0., 1., 0., 0., 1., 0., 0.],\n","         [1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n","          0., 0., 0., 1., 0., 1., 0., 0.],\n","         [1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n","          0., 0., 1., 0., 0., 1., 0., 0.],\n","         [1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n","          0., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n","          0., 0., 1., 0., 0., 1., 0., 0.],\n","         [1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n","          0., 0., 0., 1., 0., 1., 0., 0.],\n","         [1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n","          0., 0., 1., 0., 0., 1., 0., 0.],\n","         [0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n","          0., 0., 1., 0., 0., 1., 0., 0.],\n","         [1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n","          1., 0., 0., 1., 0., 1., 0., 0.],\n","         [0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n","          0., 0., 1., 0., 0., 1., 0., 0.]], dtype=float32)>},\n"," <tf.Tensor: id=52, shape=(32, 5), dtype=float32, numpy=\n"," array([[0., 1., 0., 0., 0.],\n","        [0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1.],\n","        [0., 0., 0., 0., 1.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1.],\n","        [0., 0., 0., 1., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 1.],\n","        [0., 0., 0., 1., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 1.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 1.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 1.],\n","        [0., 0., 0., 1., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 1.]], dtype=float32)>)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"TnpyqC5ivlLL","colab_type":"text"},"source":["## Construyendo el modelo\n","\n","Construimos el modelo, por ahora con sólo una capa oculta. Sin embargo, la complejidad más grande es combinar los features que tienen embeddings con los que no. Por cada tipo de feature, tenemos que agregar una capa de `Input`. Tener en cuenta que cada embedded feature se considera distinto.\n","\n","Como tenemos más de un input, tenemos que usar la API funcional de Keras en lugar de usar un modelo `Sequential`. La API funcional puede construir modelos más flexibles, ya que conectaremos explícitamente cada capa con su capa siguiente.\n","\n","Pueden encontrar otro ejemplo similar a este código en [esta notebook](https://www.kaggle.com/alexanderkireev/deep-learning-support-9663)."]},{"cell_type":"code","metadata":{"id":"b1-OOQZwvlLL","colab_type":"code","outputId":"839568d2-8867-489c-c0f1-10ffb63e8965","executionInfo":{"status":"ok","timestamp":1571233605312,"user_tz":180,"elapsed":3235,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["tf.keras.backend.clear_session()\n","\n","hidden_layer_size = 64\n","\n","# Add one input and one embedding for each embedded column\n","embedding_layers = []\n","inputs = []\n","for embedded_col, max_value in embedded_columns.items():\n","    input_layer = layers.Input(shape=(1,), name=embedded_col)\n","    inputs.append(input_layer)\n","    # Define the embedding layer\n","    embedding_size = int(max_value / 4)\n","    embedding_layers.append(\n","        tf.squeeze(layers.Embedding(input_dim=max_value, output_dim=embedding_size)(input_layer), axis=-2))\n","    print('Adding embedding of size {} for layer {}'.format(embedding_size, embedded_col))\n","\n","# Add the direct features already calculated\n","direct_features_input = layers.Input(shape=direct_features_input_shape, name='direct_features')\n","inputs.append(direct_features_input)\n","\n","# Agrego - aqui\n","for col in ['Age', 'Quantity', 'Fee']:\n","    input_num_layer = layers.Input(shape=(1,), name=col)\n","    inputs.append(input_num_layer)\n","    \n","# Concatenate everything together\n","features = layers.concatenate(embedding_layers + [direct_features_input])\n","\n","dense1 = layers.Dense(hidden_layer_size, activation='relu')(features)\n","output_layer = layers.Dense(nlabels, activation='softmax')(dense1)\n","\n","model = models.Model(inputs=inputs, outputs=output_layer)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Adding embedding of size 77 for layer Breed1\n","Adding embedding of size 77 for layer Breed2\n","Adding embedding of size 2 for layer Color1\n","Adding embedding of size 2 for layer Color2\n","Adding embedding of size 2 for layer Color3\n","Adding embedding of size 10350 for layer State\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nFjuQP7pvlLP","colab_type":"text"},"source":["### Métricas de evaluación\n","\n","Al igual que en la materia de aprendizaje supervisado, utilizaremos el accuracy como métrica, y agregaremos el score f1. Es opcional implementar esta predicción como un problema de regresión."]},{"cell_type":"code","metadata":{"id":"N6lKgE_HvlLP","colab_type":"code","outputId":"7a3afffd-c4f3-409d-bc95-dd17902d0c24","executionInfo":{"status":"ok","timestamp":1571233616525,"user_tz":180,"elapsed":973,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.compile(loss='categorical_crossentropy', optimizer='adam',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Breed1 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Breed2 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Color1 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Color2 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Color3 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","State (InputLayer)              [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1, 77)        23716       Breed2[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1, 2)         16          Color1[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 1, 2)         16          Color2[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 1, 2)         16          Color3[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_5 (Embedding)         (None, 1, 10350)     428510700   State[0][0]                      \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_1 (TensorFl [(None, 77)]         0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_2 (TensorFl [(None, 2)]          0           embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_3 (TensorFl [(None, 2)]          0           embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_4 (TensorFl [(None, 2)]          0           embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_5 (TensorFl [(None, 10350)]      0           embedding_5[0][0]                \n","__________________________________________________________________________________________________\n","direct_features (InputLayer)    [(None, 24)]         0                                            \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 10534)        0           tf_op_layer_Squeeze[0][0]        \n","                                                                 tf_op_layer_Squeeze_1[0][0]      \n","                                                                 tf_op_layer_Squeeze_2[0][0]      \n","                                                                 tf_op_layer_Squeeze_3[0][0]      \n","                                                                 tf_op_layer_Squeeze_4[0][0]      \n","                                                                 tf_op_layer_Squeeze_5[0][0]      \n","                                                                 direct_features[0][0]            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 64)           674240      concatenate[0][0]                \n","__________________________________________________________________________________________________\n","Age (InputLayer)                [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Quantity (InputLayer)           [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Fee (InputLayer)                [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 5)            325         dense[0][0]                      \n","==================================================================================================\n","Total params: 429,232,745\n","Trainable params: 429,232,745\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9y6VPAAhvlLW","colab_type":"text"},"source":["## Entrenando el modelo\n","\n","Una vez que tenemos definido nuestro modelo, tenemos que entrenarlo. Sin embargo, para que los resultados sean útiles, tenemos que llevar un registro de qué hiperparámetros utilizamos y qué performance obtuvimos. Para eso, usaremos [MLFlow](https://mlflow.org/docs/latest/quickstart.html), una librería muy simple pero que permite sistematizar el registro de resultados.\n","\n","MLFlow soporta muchísimos casos de uso, pero por ahora sólo usaremos el más básico de todos para organizar el entrenamiento. Llamaremos *experiments* a los cambios grandes en la arquitectura, por ejemplo, si agregamos muchas capas nuevas o mecanismos de regularización. Llamaremos *runs* a las distintas ejecuciones de la misma arquitectura donde variamos sólo algunos hiperparámetros, como funciones de activación, cantidad de neuronas, tamaños de los embeddings, etc.\n","\n","Para acceder a la interfaz gráfica donde podemos ver las *run*, en una nueva terminal tenemos que ejecutar \n","\n","    $ mlflow ui -p PORT\n","    \n","Y abrir `https://localhost:PORT` en nuestro navegador (donde `PORT` es un número de puerto). Si estamos en un servidor, es probab, tendremos que abrir un nuevo puerto ssh a `PORT`."]},{"cell_type":"code","metadata":{"id":"7i5Y26YcyWBw","colab_type":"code","outputId":"09485d46-690a-4be2-8675-da21e091d10d","executionInfo":{"status":"ok","timestamp":1571233647048,"user_tz":180,"elapsed":23475,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["pip install mlflow"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Collecting mlflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/eb/91b42c744e75e4523b29ca8d746a43fddb9def239adae5d5071e4044c760/mlflow-1.3.0.tar.gz (14.4MB)\n","\u001b[K     |████████████████████████████████| 14.4MB 6.6MB/s \n","\u001b[?25hCollecting alembic (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/42/48447bf41287bc577e4f340e7c28578e322567f5622a915bdfa01c83dc76/alembic-1.2.1.tar.gz (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 36.1MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (7.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.6.1)\n","Collecting databricks-cli>=0.8.7 (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/0b/75dac581d98c493be74df97f3ea515c678da2e4be8cafbaf9cba9f01c309/databricks-cli-0.9.0.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 19.5MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.21.0)\n","Requirement already satisfied: six>=1.10.0 in /tensorflow-2.0.0-rc2/python3.6 (from mlflow) (1.12.0)\n","Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.1)\n","Requirement already satisfied: numpy in /tensorflow-2.0.0-rc2/python3.6 (from mlflow) (1.17.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.24.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.5.3)\n","Requirement already satisfied: protobuf>=3.6.0 in /tensorflow-2.0.0-rc2/python3.6 (from mlflow) (3.10.0)\n","Collecting gitpython>=2.1.0 (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/f8/05f58bd7852dad7edcf70a8de953b4fa39f61cdc13812ae62118be6ffa23/GitPython-3.0.3-py3-none-any.whl (453kB)\n","\u001b[K     |████████████████████████████████| 460kB 43.1MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.13)\n","Collecting querystring_parser (from mlflow)\n","  Downloading https://files.pythonhosted.org/packages/4a/fa/f54f5662e0eababf0c49e92fd94bf178888562c0e7b677c8941bbbcd1bd6/querystring_parser-1.2.4.tar.gz\n","Collecting simplejson (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/24/c35fb1c1c315fc0fffe61ea00d3f88e85469004713dab488dee4f35b0aff/simplejson-3.16.0.tar.gz (81kB)\n","\u001b[K     |████████████████████████████████| 81kB 27.0MB/s \n","\u001b[?25hCollecting docker>=4.0.0 (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/ca/699d4754a932787ef353a157ada74efd1ceb6d1fc0bfb7989ae1e7b33111/docker-4.1.0-py2.py3-none-any.whl (139kB)\n","\u001b[K     |████████████████████████████████| 143kB 43.9MB/s \n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3)\n","Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3.0)\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.9)\n","Collecting gorilla (from mlflow)\n","  Downloading https://files.pythonhosted.org/packages/e3/56/5a683944cbfc77e429c6f03c636ca50504a785f60ffae91ddd7f5f7bb520/gorilla-0.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: gunicorn in /usr/local/lib/python3.6/dist-packages (from mlflow) (19.9.0)\n","Collecting Mako (from alembic->mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/3c/8dcd6883d009f7cae0f3157fb53e9afb05a0d3d33b3db1268ec2e6f4a56b/Mako-1.1.0.tar.gz (463kB)\n","\u001b[K     |████████████████████████████████| 471kB 43.6MB/s \n","\u001b[?25hCollecting python-editor>=0.3 (from alembic->mlflow)\n","  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.5)\n","Collecting configparser>=0.3.5 (from databricks-cli>=0.8.7->mlflow)\n","  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2019.9.11)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n","Requirement already satisfied: Werkzeug>=0.15 in /tensorflow-2.0.0-rc2/python3.6 (from Flask->mlflow) (0.16.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (2.10.3)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.1.0)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->mlflow) (2018.9)\n","Requirement already satisfied: setuptools in /tensorflow-2.0.0-rc2/python3.6 (from protobuf>=3.6.0->mlflow) (41.4.0)\n","Collecting gitdb2>=2.0.0 (from gitpython>=2.1.0->mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 28.6MB/s \n","\u001b[?25hCollecting websocket-client>=0.32.0 (from docker>=4.0.0->mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 47.6MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->mlflow) (1.1.1)\n","Collecting smmap2>=2.0.0 (from gitdb2>=2.0.0->gitpython>=2.1.0->mlflow)\n","  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n","Building wheels for collected packages: mlflow, alembic, databricks-cli, querystring-parser, simplejson, Mako\n","  Building wheel for mlflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mlflow: filename=mlflow-1.3.0-cp36-none-any.whl size=14540341 sha256=376f9a07181e301d121c9189d86f3d29522fb9c5796c456f99a72c6a3ca158ca\n","  Stored in directory: /root/.cache/pip/wheels/f1/e0/1c/663c9b2bb00f32c235c98a43c39d81c2a25544a889a32649ea\n","  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for alembic: filename=alembic-1.2.1-py2.py3-none-any.whl size=144229 sha256=b8f06ffc88ee1d4edead29f36387c5fab7b4478aae627e589426ff6ccf96e113\n","  Stored in directory: /root/.cache/pip/wheels/c6/b8/fd/1f16371156a8184172c4935cbbef6a345d57dd447e31a36633\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.9.0-cp36-none-any.whl size=83661 sha256=7ebea65efcc487d1fa89b609d53e450fa84414c424b9437a66bc116128991051\n","  Stored in directory: /root/.cache/pip/wheels/e8/ce/cd/9d2214455ef53a4d9cdbca640dc27828a6c88cd5ef7d0c04de\n","  Building wheel for querystring-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for querystring-parser: filename=querystring_parser-1.2.4-cp36-none-any.whl size=7078 sha256=7195047d64224878f9d91f03f941727b1ba4b706827d2dea115bccca8ca4b365\n","  Stored in directory: /root/.cache/pip/wheels/1e/41/34/23ebf5d1089a9aed847951e0ee375426eb4ad0a7079d88d41e\n","  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for simplejson: filename=simplejson-3.16.0-cp36-cp36m-linux_x86_64.whl size=114023 sha256=c85f89d3e3408d6643215d5742531be7972a23ad4b8eb84d8c8c0521796aefac\n","  Stored in directory: /root/.cache/pip/wheels/5d/1a/1e/0350bb3df3e74215cd91325344cc86c2c691f5306eb4d22c77\n","  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Mako: filename=Mako-1.1.0-cp36-none-any.whl size=75363 sha256=98f6e42f97aeb5cf0103d3b3a61eb83f4a359b1494e76953cea5ea2f9354d2ee\n","  Stored in directory: /root/.cache/pip/wheels/98/32/7b/a291926643fc1d1e02593e0d9e247c5a866a366b8343b7aa27\n","Successfully built mlflow alembic databricks-cli querystring-parser simplejson Mako\n","Installing collected packages: Mako, python-editor, alembic, configparser, databricks-cli, smmap2, gitdb2, gitpython, querystring-parser, simplejson, websocket-client, docker, gorilla, mlflow\n","Successfully installed Mako-1.1.0 alembic-1.2.1 configparser-4.0.2 databricks-cli-0.9.0 docker-4.1.0 gitdb2-2.0.6 gitpython-3.0.3 gorilla-0.3.0 mlflow-1.3.0 python-editor-1.0.4 querystring-parser-1.2.4 simplejson-3.16.0 smmap2-2.0.5 websocket-client-0.56.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jSZaIWIBvlLX","colab_type":"code","colab":{}},"source":["import mlflow"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tvyNaO-vlLc","colab_type":"code","outputId":"85bf276c-78b9-4697-ad85-fe52057833e6","executionInfo":{"status":"error","timestamp":1571242515452,"user_tz":180,"elapsed":8856846,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":833}},"source":["mlflow.set_experiment('very_base_approach')\n","\n","with mlflow.start_run(nested=True):\n","    # Log model hiperparameters first\n","    mlflow.log_param('hidden_layer_size', hidden_layer_size)\n","    mlflow.log_param('embedded_columns', embedded_columns)\n","    mlflow.log_param('one_hot_columns', one_hot_columns)\n","    # mlflow.log_param('numerical_columns', numerical_columns)  # Not using these yet\n","    \n","    # Train\n","    epochs = 10\n","    history = model.fit(train_ds, epochs=epochs)\n","    \n","    # Evaluate\n","    loss, accuracy = model.evaluate(test_ds)\n","    print(\"*** Test loss: {} - accuracy: {}\".format(loss, accuracy))\n","    mlflow.log_metric('epochs', epochs)\n","    mlflow.log_metric('loss', loss)\n","    mlflow.log_metric('accuracy', accuracy)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["INFO: 'very_base_approach' does not exist. Creating a new experiment\n","Epoch 1/10\n","265/265 [==============================] - 899s 3s/step - loss: 1.4638 - accuracy: 0.3054\n","Epoch 2/10\n","265/265 [==============================] - 887s 3s/step - loss: 1.4137 - accuracy: 0.3467\n","Epoch 3/10\n","265/265 [==============================] - 886s 3s/step - loss: 1.3958 - accuracy: 0.3600\n","Epoch 4/10\n","265/265 [==============================] - 886s 3s/step - loss: 1.3844 - accuracy: 0.3720\n","Epoch 5/10\n","265/265 [==============================] - 886s 3s/step - loss: 1.3746 - accuracy: 0.3755\n","Epoch 6/10\n","265/265 [==============================] - 882s 3s/step - loss: 1.3671 - accuracy: 0.3786\n","Epoch 7/10\n","265/265 [==============================] - 883s 3s/step - loss: 1.3600 - accuracy: 0.3823\n","Epoch 8/10\n","265/265 [==============================] - 883s 3s/step - loss: 1.3523 - accuracy: 0.3856\n","Epoch 9/10\n","265/265 [==============================] - 874s 3s/step - loss: 1.3464 - accuracy: 0.3914\n","Epoch 10/10\n","265/265 [==============================] - 875s 3s/step - loss: 1.3402 - accuracy: 0.3918\n","27/67 [===========>..................] - ETA: 21s - loss: 1.4226 - accuracy: 0.3510"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-13a441f64040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*** Test loss: {} - accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   def predict(self,\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     return self._model_iteration(\n\u001b[1;32m    455\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         sample_weight=sample_weight, steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[21,0] = 41415 is not in [0, 41402)\n\t [[node model/embedding_5/embedding_lookup (defined at /tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/framework/ops.py:1751) ]]\n  (1) Invalid argument:  indices[21,0] = 41415 is not in [0, 41402)\n\t [[node model/embedding_5/embedding_lookup (defined at /tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/framework/ops.py:1751) ]]\n\t [[model/embedding_5/embedding_lookup/_38]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_10523]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"]}]},{"cell_type":"markdown","metadata":{"id":"ToZNkLyUvlLf","colab_type":"text"},"source":["## Evaluando del modelo\n","\n","Además de tener en cuenta las métricas de performance del modelo, es importante mirar los resultados obtenidos y controlar que el modelo efectivamente está aprendiendo algo relevante."]},{"cell_type":"code","metadata":{"id":"2hClBzYIvlLg","colab_type":"code","colab":{}},"source":["predictions = numpy.argmax(model.predict(test_ds), axis=1)\n","seaborn.countplot(predictions)"],"execution_count":0,"outputs":[]}]}