{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"TP_AP_Kaggle_TXT.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yr_e2op1jcQb","colab_type":"text"},"source":["# Práctico 2 - Redes en escalera avanzadas\n","\n","Este práctico es similar al práctico 1, pero agregará un paso extra que es el uso de redes en escalera avanzadas, ya sean Redes Convolucionales o Redes Recurrentes.\n","\n","Se les dará, como base, el mismo conjunto de datos de la competencia \"PetFinder\" que se trabajó para el práctico 1, con el agregado de, en este caso, utilizar la descripción como un feature extra y todo el procesamiento que ello requiere.\n","\n","Ahora bien, no es el único conjunto de datos que pueden trabajar. Si tienen un conjunto propio de datos que quieran utilizar y dicho conjunto se preste para el uso de alguna red en escalera avanzada (e.g. conjuntos que tengan imágenes o texto), son libres de hacerlo."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"wbFkFbnEjcQe","colab_type":"code","outputId":"0d454253-dd78-4c7e-b519-cd2a0f2e0556","executionInfo":{"status":"ok","timestamp":1571585703141,"user_tz":180,"elapsed":3433,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import nltk\n","import numpy as np\n","import os\n","import pandas as pd\n","import tensorflow as tf\n","\n","from IPython.display import SVG\n","from gensim import corpora\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","from pprint import pprint\n","\n","nltk.download([\"punkt\", \"stopwords\"]);"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E1VdxmIuvUlH","colab_type":"code","outputId":"f5da6d48-e1e8-4f90-9770-2b38898e03f4","executionInfo":{"status":"ok","timestamp":1571585706443,"user_tz":180,"elapsed":1306,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["try:\n","    # %tensorflow_version only exists in Colab.\n","    %tensorflow_version 2.x\n","except Exception:\n","    pass\n","import tensorflow as tf\n","\n","from tensorflow.keras import layers, models"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SRmZNT9RjcQl","colab_type":"text"},"source":["## Carga de los datos"]},{"cell_type":"code","metadata":{"id":"MJmpQD-WjcQm","colab_type":"code","colab":{}},"source":["DATA_DIRECTORY = '../petfinder_dataset/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4KkzJBu5-WVz","colab_type":"code","outputId":"f206fc52-ee1b-4fc6-c6cb-00a6c7aceccf","executionInfo":{"status":"ok","timestamp":1571585816870,"user_tz":180,"elapsed":104119,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74}},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-d7982db2-8784-4e59-9d0e-e357ea8a7e2c\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-d7982db2-8784-4e59-9d0e-e357ea8a7e2c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving train.csv to train.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"32FkLO-K-dK4","colab_type":"code","outputId":"00c28c47-db25-4994-f6e7-cb9c898c8fa8","executionInfo":{"status":"ok","timestamp":1571585839186,"user_tz":180,"elapsed":1282,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":142}},"source":["import io\n","\n","dataset = pd.read_csv(io.BytesIO(os.path.join(uploaded['train.csv'])))\n","\n","target_col = 'AdoptionSpeed'\n","nlabels = dataset[target_col].unique().shape[0]\n","\n","dataset.head(3)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>Age</th>\n","      <th>Breed1</th>\n","      <th>Breed2</th>\n","      <th>Gender</th>\n","      <th>Color1</th>\n","      <th>Color2</th>\n","      <th>Color3</th>\n","      <th>MaturitySize</th>\n","      <th>FurLength</th>\n","      <th>Vaccinated</th>\n","      <th>Dewormed</th>\n","      <th>Sterilized</th>\n","      <th>Health</th>\n","      <th>Quantity</th>\n","      <th>Fee</th>\n","      <th>State</th>\n","      <th>Description</th>\n","      <th>AdoptionSpeed</th>\n","      <th>PID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>299</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>100</td>\n","      <td>41326</td>\n","      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>307</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>150</td>\n","      <td>41401</td>\n","      <td>Good guard dog, very alert, active, obedience ...</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>307</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>41326</td>\n","      <td>This handsome yet cute boy is up for adoption....</td>\n","      <td>2</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Type  Age  ...  AdoptionSpeed  PID\n","0     2    3  ...              2    0\n","1     1    4  ...              2    3\n","2     1    1  ...              2    4\n","\n","[3 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"LJ2lQ6ajjcQp","colab_type":"code","colab":{}},"source":["dataset = pd.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv'))\n","\n","target_col = 'AdoptionSpeed'\n","nlabels = dataset[target_col].unique().shape[0]\n","\n","dataset.head(3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O-o38kmdjcQs","colab_type":"text"},"source":["## Preproceso del texto para agregarlo como feature (manejo de secuencias)\n","\n","A diferencia del práctico anterior, en este caso es necesario utilizar el texto como feature extra. Pueden luego agregarlo a una red recurrente o convolucional y concatenar su salida a los atributos \"escalares\" (como \"raza\" o \"género\").\n","\n","A continuación les mostraremos los pasos a seguir para ello. La descripción detallada de para que sirve cada paso se encuentra disponible en el [notebook 3](./3_cnns.ipynb).\n","\n","### Tokenización"]},{"cell_type":"code","metadata":{"id":"5b_psUctjcQt","colab_type":"code","colab":{}},"source":["SW = set(stopwords.words(\"english\"))\n","\n","def tokenize_description(description):\n","    return [w.lower() for w in word_tokenize(description, language=\"english\") if w.lower() not in SW]\n","\n","# Fill the null values with the empty string to avoid errors with NLTK tokenization\n","dataset[\"TokenizedDescription\"] = dataset[\"Description\"].fillna(value=\"\").apply(tokenize_description)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wvfONxa4jcQx","colab_type":"text"},"source":["#### Tamaño de las descripciones\n","\n","Un punto importante a tener en cuenta es que las descripciones tienen tamaño variable, y esto no es compatible con los algoritmos de aprendizaje automático. Por lo que hay que llevar las secuencias a un tamaño uniforme.\n","\n","Para definir dicho tamaño uniforme, es útil mirar qué tamaños mínimos, máximos y medios manejan las descripciones y a partir de esto establecer el tamaño máximo de la secuencia."]},{"cell_type":"code","metadata":{"id":"s4nT5hw3jcQy","colab_type":"code","outputId":"b8405970-929d-42d0-847c-9810c7fabb3c","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1571585874766,"user_tz":180,"elapsed":1346,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}}},"source":["pprint(dataset[\"TokenizedDescription\"].apply(len).describe())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["count    10582.000000\n","mean        44.418541\n","std         48.464623\n","min          0.000000\n","25%         16.000000\n","50%         31.000000\n","75%         55.000000\n","max        803.000000\n","Name: TokenizedDescription, dtype: float64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2gU93yY4jcQ3","colab_type":"text"},"source":["Vemos que más del 75% de las secuencias tienen 55 palabras o menos. Esto es un buen punto de partida, así que podemos establecer el tamaño máximo de las secuencia en 55 palabras."]},{"cell_type":"code","metadata":{"id":"oqtQHueojcQ4","colab_type":"code","colab":{}},"source":["MAX_SEQUENCE_LEN = 55"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o8S2SySvjcQ6","colab_type":"text"},"source":["## Vocabulario"]},{"cell_type":"code","metadata":{"id":"Q6QzpphmjcQ7","colab_type":"code","colab":{}},"source":["vocabulary = corpora.Dictionary(dataset[\"TokenizedDescription\"])\n","vocabulary.filter_extremes(no_below=1, no_above=1.0, keep_n=10000)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LstJBm6ojcQ-","colab_type":"text"},"source":["## Word Embeddings (GloVe)"]},{"cell_type":"code","metadata":{"id":"mftTOX-QDsGH","colab_type":"code","outputId":"19d0afe7-23f1-45ed-b931-9e7a3ef19970","executionInfo":{"status":"ok","timestamp":1571591839543,"user_tz":180,"elapsed":5952629,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":74}},"source":["from google.colab import files\n","glove = files.upload()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-59e5c6d9-7c94-49f6-8d36-c40cf881d445\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-59e5c6d9-7c94-49f6-8d36-c40cf881d445\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving glove.6B.100d.txt to glove.6B.100d.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6ApdKoD3Dw7t","colab_type":"code","colab":{}},"source":["import io\n","\n","glove_file = io.BytesIO(os.path.join(glove['glove.6B.100d.txt']))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ME0tDuP-jcQ_","colab_type":"code","outputId":"51605cc9-7aca-4ac0-df69-ae9ed634fcdd","executionInfo":{"status":"ok","timestamp":1571592813115,"user_tz":180,"elapsed":4593,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["embeddings_index = {}\n","\n","#with open(\"./dataset/glove.6B.100d.txt\", \"r\") as fh:\n","with open(\"glove.6B.100d.txt\", \"r\") as fh:\n","    for line in fh:\n","        values = line.split()\n","        word = values[0]\n","        if word in vocabulary.token2id:  # Only use the embeddings of words in our vocabulary\n","            coefs = np.asarray(values[1:], dtype='float32')\n","            embeddings_index[word] = coefs\n","\n","print(\"Found {} word vectors.\".format(len(embeddings_index)))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Found 7897 word vectors.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qFAkr8e_jcRE","colab_type":"text"},"source":["## Creación de los datasets\n","\n","Similar al práctico anterior, tendremos datos que serán \"one-hot-encoded\", otros serán \"embeddings\" y otros serán numéricos.\n","\n","El caso particular del texto es que será tratado como una secuencia de embeddings, y dichos embeddings no serán entrenados en conjunto con la red, sino que serán tomados de un modelo \"pre-entrenado\". En este caso utilizamos GloVe, pero podríamos haber utilizado otro modelo (e.g. FastText)."]},{"cell_type":"code","metadata":{"id":"6pelssGejcRF","colab_type":"code","colab":{}},"source":["# It's important to always use the same one-hot length\n","one_hot_columns = {\n","    one_hot_col: dataset[one_hot_col].max()\n","    for one_hot_col in ['Type', 'Gender', 'MaturitySize', 'FurLength', \n","                        'Vaccinated', 'Dewormed', 'Sterilized', 'Health']\n","}\n","embedded_columns = {\n","    embedded_col: dataset[embedded_col].max() + 1\n","    for embedded_col in ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'State']\n","}\n","numeric_columns = ['Age', 'Quantity', 'Fee']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bDXlReJxjcRI","colab_type":"text"},"source":["## Generador del conjunto de datos\n","\n","Dada la naturaleza de los datos de texto, y que estos representan una secuencia de datos (que se da luego a una red recurrente o convolucional), en este caso no crearemos los datasets de antemano, sino que los generaremos a medida que el algoritmo de entrenamiento los pida. \n","\n","En particular, es porque las secuencias de texto pueden no tener el mismo tamaño (las oraciones tienen diferente cantidad de palabras), pero para que los modelos de redes las acepten, necesitamos rellenarlas (*padding*) de manera que todas tengan el mismo tamaño.\n","\n","En este paso también vamos a truncar aquellas secuencias de descripciones con más de `MAX_SEQUENCE_LEN` palabras, de manera que al hacer uso de `padded_batch` no lance un error al encontrarse con secuencias de tamaño mayor."]},{"cell_type":"code","metadata":{"id":"E5ykXHOnjcRJ","colab_type":"code","colab":{}},"source":["def dataset_generator(ds, test_data=False):\n","    for _, row in ds.iterrows():\n","        instance = {}\n","        \n","        # One hot encoded features\n","        instance[\"direct_features\"] = np.hstack([\n","            tf.keras.utils.to_categorical(row[one_hot_col] - 1, max_value)\n","            for one_hot_col, max_value in one_hot_columns.items()\n","        ])\n","\n","        # Numeric features (should be normalized beforehand)\n","        # TODO: Add numeric features for row\n","        \n","        # Embedded features\n","        for embedded_col in embedded_columns:\n","            instance[embedded_col] = [row[embedded_col]]\n","\n","        # DONE\n","        for n_col in numeric_columns:\n","            instance[n_col] = numpy.hstack(tf.keras.utils.normalize(df[n_col].values)) \n","        \n","        # Document to indices for text data, truncated at MAX_SEQUENCE_LEN words\n","        instance[\"description\"] = vocabulary.doc2idx(\n","            row[\"TokenizedDescription\"],\n","            unknown_word_index=len(vocabulary)\n","        )[:MAX_SEQUENCE_LEN]\n","        \n","        # One hot encoded target for categorical crossentropy\n","        if not test_data:\n","            target = tf.keras.utils.to_categorical(row[target_col], nlabels)\n","            yield instance, target\n","        else:\n","            yield instance\n","\n","# Set output types of the generator (for numeric types check the type is valid)\n","instance_types = {\n","    \"direct_features\": tf.float32,\n","    \"description\": tf.int32\n","}\n","\n","for embedded_col in embedded_columns:\n","    instance_types[embedded_col] = tf.int32\n","\n","for n_col in numeric_columns:\n","    instance_types[n_col] = tf.int32\n","        \n","tf_dataset = tf.data.Dataset.from_generator(\n","    lambda: dataset_generator(dataset),\n","    output_types=(instance_types, tf.int32)\n",")\n","\n","#for data, target in tf_dataset.take(2):\n","#    pprint(data)\n","#    pprint(target)\n","#    print()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hdYxXEsljcRM","colab_type":"text"},"source":["## Datos de entrenamiento y validación\n","\n","Ya generado el conjunto de datos base, tenemos que dividirlo en entrenamiento y validación. Además, como vamos a utilizar algunos datos que forman secuencias, los lotes (*batches*) de datos deben estar \"rellenados\" (*padded_batch*). \n","\n","Si bien rellenaremos \"todos\" los atributos, en la práctica el único que efectivamente se rellenará es el de *description* pues es el único con tamaños distintos."]},{"cell_type":"code","metadata":{"id":"uubyx9wnjcRN","colab_type":"code","outputId":"509cf97b-a681-4bb0-dd9d-c4ef775904dd","executionInfo":{"status":"ok","timestamp":1571592831738,"user_tz":180,"elapsed":2733,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["TRAIN_SIZE = int(dataset.shape[0] * 0.8)\n","DEV_SIZE = dataset.shape[0] - TRAIN_SIZE\n","BATCH_SIZE = 128\n","\n","shuffled_dataset = tf_dataset.shuffle(TRAIN_SIZE + DEV_SIZE, seed=42)\n","\n","#Agrego\n","# Pad the datasets to the max value for all the \"non sequence\" features\n","padding_shapes = (\n","    {k: [-1] for k in [\"direct_features\"] + list(embedded_columns.keys()) + numeric_columns},\n","    [-1]\n",")\n","\n","# Pad to MAX_SEQUENCE_LEN for sequence features\n","padding_shapes[0][\"description\"] = [MAX_SEQUENCE_LEN]\n","\n","# Pad values are irrelevant for non padded data\n","padding_values = (\n","    {k: 0 for k in list(embedded_columns.keys())},\n","    0\n",")\n","\n","# Padding value for direct features should be a float\n","padding_values[0][\"direct_features\"] = np.float32(0)\n","\n","# Padding value for sequential features is the vocabulary length + 1\n","padding_values[0][\"description\"] = len(vocabulary) + 1\n","\n","#Agrego\n","padding_values[0][\"Age\"] = np.int32(0)\n","padding_values[0][\"Fee\"] = np.int32(0)\n","padding_values[0][\"Quantity\"] = np.int32(0)\n","\n","print(padding_shapes)\n","print(padding_values)\n","train_dataset = shuffled_dataset.skip(DEV_SIZE)\\\n","    .padded_batch(BATCH_SIZE, padded_shapes=padding_shapes, padding_values=padding_values)\n","\n","dev_dataset = shuffled_dataset.take(DEV_SIZE)\\\n","    .padded_batch(BATCH_SIZE, padded_shapes=padding_shapes, padding_values=padding_values)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","({'direct_features': [-1], 'Breed1': [-1], 'Breed2': [-1], 'Color1': [-1], 'Color2': [-1], 'Color3': [-1], 'State': [-1], 'Age': [-1], 'Quantity': [-1], 'Fee': [-1], 'description': [55]}, [-1])\n","({'Breed1': 0, 'Breed2': 0, 'Color1': 0, 'Color2': 0, 'Color3': 0, 'State': 0, 'direct_features': 0.0, 'description': 10001, 'Age': 0, 'Fee': 0, 'Quantity': 0}, 0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BS1IyRBpjcRQ","colab_type":"text"},"source":["## Construyendo el modelo\n","\n","Al modelo anterior tenemos que agregarle la capa que maneje los embeddings de las palabras, e inicializarla de manera acorde, podemos guiarnos por lo visto en el [notebook 3](./3_cnns.ipynb) para hacer esto.\n","\n","### Matriz de embeddings de palabras"]},{"cell_type":"code","metadata":{"id":"0Q-IncHyjcRR","colab_type":"code","colab":{}},"source":["EMBEDDINGS_DIM = 100  # Given by the model (in this case glove.6B.100d)\n","\n","embedding_matrix = np.zeros((len(vocabulary) + 2, 100))\n","\n","for widx, word in vocabulary.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[widx] = embedding_vector\n","    else:\n","        # Random normal initialization for words without embeddings\n","        embedding_matrix[widx] = np.random.normal(size=(100,))  \n","\n","# Random normal initialization for unknown words\n","embedding_matrix[len(vocabulary)] = np.random.normal(size=(100,))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"myVabjLYjcRV","colab_type":"text"},"source":["### Definiendo los inputs del modelo\n","\n","Definamos los inputs del modelo, con el agregado de la capa de embeddings de palabras inicializada en `embedding_matrix`."]},{"cell_type":"code","metadata":{"id":"zdvtRtvrjcRW","colab_type":"code","outputId":"bd620c03-010a-43a9-934c-72eabe073565","executionInfo":{"status":"ok","timestamp":1571592846293,"user_tz":180,"elapsed":5655,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["tf.keras.backend.clear_session()\n","\n","# Add one input and one embedding for each embedded column\n","embedding_layers = []\n","numeric_layer = []\n","inputs = []\n","for embedded_col, max_value in embedded_columns.items():\n","    input_layer = tf.keras.layers.Input(shape=(1,), name=embedded_col)\n","    inputs.append(input_layer)\n","    # Define the embedding layer\n","    embedding_size = int(max_value / 4)\n","    embedding_layers.append(\n","        tf.squeeze(\n","            tf.keras.layers.Embedding(\n","                input_dim=max_value, \n","                output_dim=embedding_size\n","            )(input_layer), \n","            axis=-2\n","        )\n","    )\n","    print('Adding embedding of size {} for layer {}'.format(embedding_size, embedded_col))\n","\n","# Add the direct features already calculated\n","direct_features_input = tf.keras.layers.Input(\n","    shape=(sum(one_hot_columns.values()),), \n","    name='direct_features'\n",")\n","inputs.append(direct_features_input)\n","\n","# DONE: Add Numerics\n","for col in numeric_columns:\n","    input_num_layer = tf.keras.layers.Input(shape=(1,), name=col)\n","    inputs.append(input_num_layer)\n","    numeric_layer.append(input_num_layer)\n","\n","# Word embedding layer\n","description_input = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LEN,), name=\"description\")\n","inputs.append(description_input)\n","\n","word_embeddings_layer = tf.keras.layers.Embedding(\n","    embedding_matrix.shape[0],\n","    EMBEDDINGS_DIM,\n","    weights=[embedding_matrix],\n","    input_length=MAX_SEQUENCE_LEN,\n","    trainable=False,\n","    name=\"word_embedding\"\n",")(description_input)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Adding embedding of size 77 for layer Breed1\n","Adding embedding of size 77 for layer Breed2\n","Adding embedding of size 2 for layer Color1\n","Adding embedding of size 2 for layer Color2\n","Adding embedding of size 2 for layer Color3\n","Adding embedding of size 10354 for layer State\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gL3BBNDwjcRZ","colab_type":"text"},"source":["### Definiendo la red que trabajará con el texto\n","\n","Antes de generar el *feature map* final entre los inputs y las clases, tenemos que generar el *feature map* de las secuencias de texto. \n","\n","Para ello pueden utilizar una red neuronal recurrente o convolucional.\n","\n","Pueden pensar dicha red como un submodelo del modelo general que se encarga de generar los atributos que representan la descripción de la mascota (recordemos que las redes se utilizan para hacer aprendizaje de representaciones).\n","\n","La red puede ser tan compleja como ustedes lo consideren pertinente."]},{"cell_type":"code","metadata":{"id":"lyDzENoQjcRa","colab_type":"code","colab":{}},"source":["## TODO: Create a NN (CNN or RNN) for the description input (replace the next)\n","DESCRIPTION_FEATURES_LAYER_SIZE = 512\n","\n","description_features = tf.keras.layers.Flatten()(word_embeddings_layer)  # This is a simple concatenation\n","description_features = tf.keras.layers.Dense(\n","    units=DESCRIPTION_FEATURES_LAYER_SIZE, \n","    activation=\"relu\", \n","    name=\"description_features\")(description_features)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLfz3muqjcRd","colab_type":"text"},"source":["### Definiendo el *feature map* final de la red\n","\n","Ahora que tenemos nuestra representación de las descripciones, pasamos a combinarlo con los demás features en la última parte de nuestra red."]},{"cell_type":"code","metadata":{"id":"av9xWay2jcRe","colab_type":"code","colab":{}},"source":["HIDDEN_LAYER_SIZE = 128\n","\n","feature_map = tf.keras.layers.Concatenate(name=\"feature_map\")(\n","    embedding_layers + numeric_layer + [description_features, direct_features_input]\n",")\n","\n","hidden_layer = tf.keras.layers.Dense(HIDDEN_LAYER_SIZE, activation=\"relu\")(feature_map)\n","output_layer = tf.keras.layers.Dense(nlabels, activation=\"softmax\", name=\"output\")(hidden_layer)\n","\n","model = tf.keras.models.Model(inputs=inputs, outputs=[output_layer], name=\"amazing_model\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"znr-tvvrjcRh","colab_type":"text"},"source":["### Compilando y visualizando el modelo"]},{"cell_type":"code","metadata":{"id":"dvCJu49njcRj","colab_type":"code","outputId":"80b83047-b6f5-4be8-b449-ff09958da326","executionInfo":{"status":"ok","timestamp":1571592857768,"user_tz":180,"elapsed":941,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.compile(loss='categorical_crossentropy', \n","              optimizer='nadam',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Model: \"amazing_model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","description (InputLayer)        [(None, 55)]         0                                            \n","__________________________________________________________________________________________________\n","Breed1 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Breed2 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Color1 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Color2 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Color3 (InputLayer)             [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","State (InputLayer)              [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","word_embedding (Embedding)      (None, 55, 100)      1000200     description[0][0]                \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1, 77)        23716       Breed2[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 1, 2)         16          Color1[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, 1, 2)         16          Color2[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_4 (Embedding)         (None, 1, 2)         16          Color3[0][0]                     \n","__________________________________________________________________________________________________\n","embedding_5 (Embedding)         (None, 1, 10354)     428821264   State[0][0]                      \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 5500)         0           word_embedding[0][0]             \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_1 (TensorFl [(None, 77)]         0           embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_2 (TensorFl [(None, 2)]          0           embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_3 (TensorFl [(None, 2)]          0           embedding_3[0][0]                \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_4 (TensorFl [(None, 2)]          0           embedding_4[0][0]                \n","__________________________________________________________________________________________________\n","tf_op_layer_Squeeze_5 (TensorFl [(None, 10354)]      0           embedding_5[0][0]                \n","__________________________________________________________________________________________________\n","Age (InputLayer)                [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Quantity (InputLayer)           [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","Fee (InputLayer)                [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","description_features (Dense)    (None, 512)          2816512     flatten[0][0]                    \n","__________________________________________________________________________________________________\n","direct_features (InputLayer)    [(None, 24)]         0                                            \n","__________________________________________________________________________________________________\n","feature_map (Concatenate)       (None, 11053)        0           tf_op_layer_Squeeze[0][0]        \n","                                                                 tf_op_layer_Squeeze_1[0][0]      \n","                                                                 tf_op_layer_Squeeze_2[0][0]      \n","                                                                 tf_op_layer_Squeeze_3[0][0]      \n","                                                                 tf_op_layer_Squeeze_4[0][0]      \n","                                                                 tf_op_layer_Squeeze_5[0][0]      \n","                                                                 Age[0][0]                        \n","                                                                 Quantity[0][0]                   \n","                                                                 Fee[0][0]                        \n","                                                                 description_features[0][0]       \n","                                                                 direct_features[0][0]            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 128)          1414912     feature_map[0][0]                \n","__________________________________________________________________________________________________\n","output (Dense)                  (None, 5)            645         dense[0][0]                      \n","==================================================================================================\n","Total params: 434,101,013\n","Trainable params: 433,100,813\n","Non-trainable params: 1,000,200\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n4_mAl1-jcRp","colab_type":"code","outputId":"93ff4c90-ca35-4e36-cf7b-16f8b8a8e233","executionInfo":{"status":"ok","timestamp":1571531113705,"user_tz":180,"elapsed":1014,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":577}},"source":["SVG(tf.keras.utils.model_to_dot(model, dpi=60).create(prog='dot', format='svg'))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.SVG object>"],"image/svg+xml":"<svg height=\"402pt\" viewBox=\"0.00 0.00 2565.00 483.00\" width=\"2138pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 479)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-479 2561,-479 2561,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140542605380968 -->\n<g class=\"node\" id=\"node1\">\n<title>140542605380968</title>\n<polygon fill=\"none\" points=\"21.5,-438.5 21.5,-474.5 172.5,-474.5 172.5,-438.5 21.5,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-452.8\">description: InputLayer</text>\n</g>\n<!-- 140542605456944 -->\n<g class=\"node\" id=\"node8\">\n<title>140542605456944</title>\n<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 194,-401.5 194,-365.5 0,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-379.8\">word_embedding: Embedding</text>\n</g>\n<!-- 140542605380968&#45;&gt;140542605456944 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140542605380968-&gt;140542605456944</title>\n<path d=\"M97,-438.4551C97,-430.3828 97,-420.6764 97,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"100.5001,-411.5903 97,-401.5904 93.5001,-411.5904 100.5001,-411.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605687776 -->\n<g class=\"node\" id=\"node2\">\n<title>140542605687776</title>\n<polygon fill=\"none\" points=\"269.5,-365.5 269.5,-401.5 398.5,-401.5 398.5,-365.5 269.5,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334\" y=\"-379.8\">Breed1: InputLayer</text>\n</g>\n<!-- 140542605688112 -->\n<g class=\"node\" id=\"node9\">\n<title>140542605688112</title>\n<polygon fill=\"none\" points=\"256,-292.5 256,-328.5 412,-328.5 412,-292.5 256,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334\" y=\"-306.8\">embedding: Embedding</text>\n</g>\n<!-- 140542605687776&#45;&gt;140542605688112 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140542605687776-&gt;140542605688112</title>\n<path d=\"M334,-365.4551C334,-357.3828 334,-347.6764 334,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"337.5001,-338.5903 334,-328.5904 330.5001,-338.5904 337.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605823784 -->\n<g class=\"node\" id=\"node3\">\n<title>140542605823784</title>\n<polygon fill=\"none\" points=\"560.5,-365.5 560.5,-401.5 689.5,-401.5 689.5,-365.5 560.5,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625\" y=\"-379.8\">Breed2: InputLayer</text>\n</g>\n<!-- 140542605822328 -->\n<g class=\"node\" id=\"node10\">\n<title>140542605822328</title>\n<polygon fill=\"none\" points=\"539.5,-292.5 539.5,-328.5 710.5,-328.5 710.5,-292.5 539.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625\" y=\"-306.8\">embedding_1: Embedding</text>\n</g>\n<!-- 140542605823784&#45;&gt;140542605822328 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140542605823784-&gt;140542605822328</title>\n<path d=\"M625,-365.4551C625,-357.3828 625,-347.6764 625,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"628.5001,-338.5903 625,-328.5904 621.5001,-338.5904 628.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605729072 -->\n<g class=\"node\" id=\"node4\">\n<title>140542605729072</title>\n<polygon fill=\"none\" points=\"859,-365.5 859,-401.5 987,-401.5 987,-365.5 859,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"923\" y=\"-379.8\">Color1: InputLayer</text>\n</g>\n<!-- 140542605716504 -->\n<g class=\"node\" id=\"node11\">\n<title>140542605716504</title>\n<polygon fill=\"none\" points=\"837.5,-292.5 837.5,-328.5 1008.5,-328.5 1008.5,-292.5 837.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"923\" y=\"-306.8\">embedding_2: Embedding</text>\n</g>\n<!-- 140542605729072&#45;&gt;140542605716504 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140542605729072-&gt;140542605716504</title>\n<path d=\"M923,-365.4551C923,-357.3828 923,-347.6764 923,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"926.5001,-338.5903 923,-328.5904 919.5001,-338.5904 926.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605753424 -->\n<g class=\"node\" id=\"node5\">\n<title>140542605753424</title>\n<polygon fill=\"none\" points=\"1157,-365.5 1157,-401.5 1285,-401.5 1285,-365.5 1157,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1221\" y=\"-379.8\">Color2: InputLayer</text>\n</g>\n<!-- 140542605754320 -->\n<g class=\"node\" id=\"node12\">\n<title>140542605754320</title>\n<polygon fill=\"none\" points=\"1135.5,-292.5 1135.5,-328.5 1306.5,-328.5 1306.5,-292.5 1135.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1221\" y=\"-306.8\">embedding_3: Embedding</text>\n</g>\n<!-- 140542605753424&#45;&gt;140542605754320 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140542605753424-&gt;140542605754320</title>\n<path d=\"M1221,-365.4551C1221,-357.3828 1221,-347.6764 1221,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1224.5001,-338.5903 1221,-328.5904 1217.5001,-338.5904 1224.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542655707288 -->\n<g class=\"node\" id=\"node6\">\n<title>140542655707288</title>\n<polygon fill=\"none\" points=\"1455,-365.5 1455,-401.5 1583,-401.5 1583,-365.5 1455,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1519\" y=\"-379.8\">Color3: InputLayer</text>\n</g>\n<!-- 140542605305280 -->\n<g class=\"node\" id=\"node13\">\n<title>140542605305280</title>\n<polygon fill=\"none\" points=\"1433.5,-292.5 1433.5,-328.5 1604.5,-328.5 1604.5,-292.5 1433.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1519\" y=\"-306.8\">embedding_4: Embedding</text>\n</g>\n<!-- 140542655707288&#45;&gt;140542605305280 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140542655707288-&gt;140542605305280</title>\n<path d=\"M1519,-365.4551C1519,-357.3828 1519,-347.6764 1519,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1522.5001,-338.5903 1519,-328.5904 1515.5001,-338.5904 1522.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605354040 -->\n<g class=\"node\" id=\"node7\">\n<title>140542605354040</title>\n<polygon fill=\"none\" points=\"1759,-365.5 1759,-401.5 1875,-401.5 1875,-365.5 1759,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1817\" y=\"-379.8\">State: InputLayer</text>\n</g>\n<!-- 140542605354544 -->\n<g class=\"node\" id=\"node14\">\n<title>140542605354544</title>\n<polygon fill=\"none\" points=\"1731.5,-292.5 1731.5,-328.5 1902.5,-328.5 1902.5,-292.5 1731.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1817\" y=\"-306.8\">embedding_5: Embedding</text>\n</g>\n<!-- 140542605354040&#45;&gt;140542605354544 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140542605354040-&gt;140542605354544</title>\n<path d=\"M1817,-365.4551C1817,-357.3828 1817,-347.6764 1817,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1820.5001,-338.5903 1817,-328.5904 1813.5001,-338.5904 1820.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605847016 -->\n<g class=\"node\" id=\"node15\">\n<title>140542605847016</title>\n<polygon fill=\"none\" points=\"48,-292.5 48,-328.5 146,-328.5 146,-292.5 48,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-306.8\">flatten: Flatten</text>\n</g>\n<!-- 140542605456944&#45;&gt;140542605847016 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140542605456944-&gt;140542605847016</title>\n<path d=\"M97,-365.4551C97,-357.3828 97,-347.6764 97,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"100.5001,-338.5903 97,-328.5904 93.5001,-338.5904 100.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605067656 -->\n<g class=\"node\" id=\"node16\">\n<title>140542605067656</title>\n<polygon fill=\"none\" points=\"201.5,-219.5 201.5,-255.5 466.5,-255.5 466.5,-219.5 201.5,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334\" y=\"-233.8\">tf_op_layer_Squeeze: TensorFlowOpLayer</text>\n</g>\n<!-- 140542605688112&#45;&gt;140542605067656 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140542605688112-&gt;140542605067656</title>\n<path d=\"M334,-292.4551C334,-284.3828 334,-274.6764 334,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"337.5001,-265.5903 334,-255.5904 330.5001,-265.5904 337.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605067992 -->\n<g class=\"node\" id=\"node17\">\n<title>140542605067992</title>\n<polygon fill=\"none\" points=\"485,-219.5 485,-255.5 765,-255.5 765,-219.5 485,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625\" y=\"-233.8\">tf_op_layer_Squeeze_1: TensorFlowOpLayer</text>\n</g>\n<!-- 140542605822328&#45;&gt;140542605067992 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140542605822328-&gt;140542605067992</title>\n<path d=\"M625,-292.4551C625,-284.3828 625,-274.6764 625,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"628.5001,-265.5903 625,-255.5904 621.5001,-265.5904 628.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605068720 -->\n<g class=\"node\" id=\"node18\">\n<title>140542605068720</title>\n<polygon fill=\"none\" points=\"783,-219.5 783,-255.5 1063,-255.5 1063,-219.5 783,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"923\" y=\"-233.8\">tf_op_layer_Squeeze_2: TensorFlowOpLayer</text>\n</g>\n<!-- 140542605716504&#45;&gt;140542605068720 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140542605716504-&gt;140542605068720</title>\n<path d=\"M923,-292.4551C923,-284.3828 923,-274.6764 923,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"926.5001,-265.5903 923,-255.5904 919.5001,-265.5904 926.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605069336 -->\n<g class=\"node\" id=\"node19\">\n<title>140542605069336</title>\n<polygon fill=\"none\" points=\"1081,-219.5 1081,-255.5 1361,-255.5 1361,-219.5 1081,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1221\" y=\"-233.8\">tf_op_layer_Squeeze_3: TensorFlowOpLayer</text>\n</g>\n<!-- 140542605754320&#45;&gt;140542605069336 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140542605754320-&gt;140542605069336</title>\n<path d=\"M1221,-292.4551C1221,-284.3828 1221,-274.6764 1221,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1224.5001,-265.5903 1221,-255.5904 1217.5001,-265.5904 1224.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605069952 -->\n<g class=\"node\" id=\"node20\">\n<title>140542605069952</title>\n<polygon fill=\"none\" points=\"1379,-219.5 1379,-255.5 1659,-255.5 1659,-219.5 1379,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1519\" y=\"-233.8\">tf_op_layer_Squeeze_4: TensorFlowOpLayer</text>\n</g>\n<!-- 140542605305280&#45;&gt;140542605069952 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140542605305280-&gt;140542605069952</title>\n<path d=\"M1519,-292.4551C1519,-284.3828 1519,-274.6764 1519,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1522.5001,-265.5903 1519,-255.5904 1515.5001,-265.5904 1522.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605099304 -->\n<g class=\"node\" id=\"node21\">\n<title>140542605099304</title>\n<polygon fill=\"none\" points=\"1677,-219.5 1677,-255.5 1957,-255.5 1957,-219.5 1677,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1817\" y=\"-233.8\">tf_op_layer_Squeeze_5: TensorFlowOpLayer</text>\n</g>\n<!-- 140542605354544&#45;&gt;140542605099304 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140542605354544-&gt;140542605099304</title>\n<path d=\"M1817,-292.4551C1817,-284.3828 1817,-274.6764 1817,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1820.5001,-265.5903 1817,-255.5904 1813.5001,-265.5904 1820.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605845840 -->\n<g class=\"node\" id=\"node25\">\n<title>140542605845840</title>\n<polygon fill=\"none\" points=\"10.5,-219.5 10.5,-255.5 183.5,-255.5 183.5,-219.5 10.5,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-233.8\">description_features: Dense</text>\n</g>\n<!-- 140542605847016&#45;&gt;140542605845840 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140542605847016-&gt;140542605845840</title>\n<path d=\"M97,-292.4551C97,-284.3828 97,-274.6764 97,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"100.5001,-265.5903 97,-255.5904 93.5001,-265.5904 100.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605067096 -->\n<g class=\"node\" id=\"node27\">\n<title>140542605067096</title>\n<polygon fill=\"none\" points=\"1437,-146.5 1437,-182.5 1601,-182.5 1601,-146.5 1437,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1519\" y=\"-160.8\">feature_map: Concatenate</text>\n</g>\n<!-- 140542605067656&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140542605067656-&gt;140542605067096</title>\n<path d=\"M466.6175,-219.8935C469.774,-219.5806 472.9052,-219.282 476,-219 826.2402,-187.0827 1244.4775,-172.2449 1426.6269,-166.9276\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1426.808,-170.4239 1436.7026,-166.6362 1426.6055,-163.4268 1426.808,-170.4239\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605067992&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140542605067992-&gt;140542605067096</title>\n<path d=\"M765.3577,-219.8726C768.2631,-219.5727 771.1465,-219.2813 774,-219 1008.506,-195.8791 1285.4366,-178.1234 1426.4276,-169.7646\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1426.9781,-173.2383 1436.7544,-169.1548 1426.5654,-166.2504 1426.9781,-173.2383\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605068720&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140542605068720-&gt;140542605067096</title>\n<path d=\"M1063.3787,-220.0617C1066.2777,-219.7044 1069.1541,-219.3502 1072,-219 1194.6556,-203.9082 1336.2685,-186.6744 1426.6614,-175.6981\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1427.1023,-179.1703 1436.6075,-174.4905 1426.2585,-172.2214 1427.1023,-179.1703\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605069336&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140542605069336-&gt;140542605067096</title>\n<path d=\"M1294.6629,-219.4551C1337.3662,-208.9942 1391.2731,-195.7888 1435.5408,-184.9447\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1436.5302,-188.3059 1445.4103,-182.527 1434.8647,-181.5069 1436.5302,-188.3059\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605069952&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140542605069952-&gt;140542605067096</title>\n<path d=\"M1519,-219.4551C1519,-211.3828 1519,-201.6764 1519,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1522.5001,-192.5903 1519,-182.5904 1515.5001,-192.5904 1522.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605099304&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge21\">\n<title>140542605099304-&gt;140542605067096</title>\n<path d=\"M1743.3371,-219.4551C1700.6338,-208.9942 1646.7269,-195.7888 1602.4592,-184.9447\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1603.1353,-181.5069 1592.5897,-182.527 1601.4698,-188.3059 1603.1353,-181.5069\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605432816 -->\n<g class=\"node\" id=\"node22\">\n<title>140542605432816</title>\n<polygon fill=\"none\" points=\"1975,-219.5 1975,-255.5 2087,-255.5 2087,-219.5 1975,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2031\" y=\"-233.8\">Age: InputLayer</text>\n</g>\n<!-- 140542605432816&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge22\">\n<title>140542605432816-&gt;140542605067096</title>\n<path d=\"M1974.7617,-220.9134C1971.8086,-220.2245 1968.8752,-219.5807 1966,-219 1844.4964,-194.458 1702.0295,-179.4101 1611.1766,-171.5102\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1611.4433,-168.0204 1601.1805,-170.6518 1610.8443,-174.9947 1611.4433,-168.0204\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605433040 -->\n<g class=\"node\" id=\"node23\">\n<title>140542605433040</title>\n<polygon fill=\"none\" points=\"2105,-219.5 2105,-255.5 2243,-255.5 2243,-219.5 2105,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2174\" y=\"-233.8\">Quantity: InputLayer</text>\n</g>\n<!-- 140542605433040&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge23\">\n<title>140542605433040-&gt;140542605067096</title>\n<path d=\"M2104.7784,-220.5559C2101.8191,-219.998 2098.8837,-219.4758 2096,-219 1926.1503,-190.975 1725.6164,-176.067 1611.2717,-169.2606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1611.3454,-165.759 1601.1573,-168.6664 1610.9348,-172.747 1611.3454,-165.759\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605434160 -->\n<g class=\"node\" id=\"node24\">\n<title>140542605434160</title>\n<polygon fill=\"none\" points=\"2261,-219.5 2261,-255.5 2369,-255.5 2369,-219.5 2261,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2315\" y=\"-233.8\">Fee: InputLayer</text>\n</g>\n<!-- 140542605434160&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge24\">\n<title>140542605434160-&gt;140542605067096</title>\n<path d=\"M2260.8788,-220.8181C2257.8895,-220.1438 2254.916,-219.5304 2252,-219 2131.5795,-197.0973 1780.0432,-177.4174 1611.3774,-168.9276\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1611.4358,-165.4263 1601.2731,-168.4214 1611.0854,-172.4175 1611.4358,-165.4263\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605845840&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge25\">\n<title>140542605845840-&gt;140542605067096</title>\n<path d=\"M183.6366,-220.0682C186.4531,-219.6808 189.2464,-219.3228 192,-219 431.6896,-190.9034 1166.6489,-172.3158 1426.6644,-166.4722\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1426.9097,-169.9677 1436.8289,-166.2449 1426.7531,-162.9695 1426.9097,-169.9677\" stroke=\"#000000\"/>\n</g>\n<!-- 140542683458920 -->\n<g class=\"node\" id=\"node26\">\n<title>140542683458920</title>\n<polygon fill=\"none\" points=\"2387,-219.5 2387,-255.5 2557,-255.5 2557,-219.5 2387,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"2472\" y=\"-233.8\">direct_features: InputLayer</text>\n</g>\n<!-- 140542683458920&#45;&gt;140542605067096 -->\n<g class=\"edge\" id=\"edge26\">\n<title>140542683458920-&gt;140542605067096</title>\n<path d=\"M2386.7739,-220.2213C2383.8177,-219.7833 2380.8866,-219.374 2378,-219 2100.3071,-183.0219 1768.9009,-170.5135 1611.1997,-166.393\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1611.1522,-162.8907 1601.0658,-166.1335 1610.9729,-169.8884 1611.1522,-162.8907\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605067152 -->\n<g class=\"node\" id=\"node28\">\n<title>140542605067152</title>\n<polygon fill=\"none\" points=\"1473,-73.5 1473,-109.5 1565,-109.5 1565,-73.5 1473,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1519\" y=\"-87.8\">dense: Dense</text>\n</g>\n<!-- 140542605067096&#45;&gt;140542605067152 -->\n<g class=\"edge\" id=\"edge27\">\n<title>140542605067096-&gt;140542605067152</title>\n<path d=\"M1519,-146.4551C1519,-138.3828 1519,-128.6764 1519,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1522.5001,-119.5903 1519,-109.5904 1515.5001,-119.5904 1522.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140542605067488 -->\n<g class=\"node\" id=\"node29\">\n<title>140542605067488</title>\n<polygon fill=\"none\" points=\"1470.5,-.5 1470.5,-36.5 1567.5,-36.5 1567.5,-.5 1470.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1519\" y=\"-14.8\">output: Dense</text>\n</g>\n<!-- 140542605067152&#45;&gt;140542605067488 -->\n<g class=\"edge\" id=\"edge28\">\n<title>140542605067152-&gt;140542605067488</title>\n<path d=\"M1519,-73.4551C1519,-65.3828 1519,-55.6764 1519,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1522.5001,-46.5903 1519,-36.5904 1515.5001,-46.5904 1522.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"markdown","metadata":{"id":"_XB8t6yDjcRv","colab_type":"text"},"source":["## Entrenando el modelo\n","\n","Para entrenar el modelo es igual al caso anterior, ya generados el conjunto de datos correspondiente. Lo entrenamos con ayuda de `mlflow`."]},{"cell_type":"code","metadata":{"id":"jI5qe7_ZjhU3","colab_type":"code","outputId":"9ea29ca0-8d53-41e7-a8a3-03c64bf628df","executionInfo":{"status":"ok","timestamp":1571592887841,"user_tz":180,"elapsed":25434,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["pip install mlflow"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Collecting mlflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/eb/91b42c744e75e4523b29ca8d746a43fddb9def239adae5d5071e4044c760/mlflow-1.3.0.tar.gz (14.4MB)\n","\u001b[K     |████████████████████████████████| 14.4MB 2.7MB/s \n","\u001b[?25hCollecting alembic (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/42/48447bf41287bc577e4f340e7c28578e322567f5622a915bdfa01c83dc76/alembic-1.2.1.tar.gz (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 32.5MB/s \n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (7.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.6.1)\n","Collecting databricks-cli>=0.8.7 (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/0b/75dac581d98c493be74df97f3ea515c678da2e4be8cafbaf9cba9f01c309/databricks-cli-0.9.0.tar.gz (45kB)\n","\u001b[K     |████████████████████████████████| 51kB 19.0MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.21.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.12.0)\n","Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.16.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.24.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.5.3)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.10.0)\n","Collecting gitpython>=2.1.0 (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/f8/05f58bd7852dad7edcf70a8de953b4fa39f61cdc13812ae62118be6ffa23/GitPython-3.0.3-py3-none-any.whl (453kB)\n","\u001b[K     |████████████████████████████████| 460kB 38.8MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.13)\n","Collecting querystring_parser (from mlflow)\n","  Downloading https://files.pythonhosted.org/packages/4a/fa/f54f5662e0eababf0c49e92fd94bf178888562c0e7b677c8941bbbcd1bd6/querystring_parser-1.2.4.tar.gz\n","Collecting simplejson (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/24/c35fb1c1c315fc0fffe61ea00d3f88e85469004713dab488dee4f35b0aff/simplejson-3.16.0.tar.gz (81kB)\n","\u001b[K     |████████████████████████████████| 81kB 22.7MB/s \n","\u001b[?25hCollecting docker>=4.0.0 (from mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/ca/699d4754a932787ef353a157ada74efd1ceb6d1fc0bfb7989ae1e7b33111/docker-4.1.0-py2.py3-none-any.whl (139kB)\n","\u001b[K     |████████████████████████████████| 143kB 37.7MB/s \n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3)\n","Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3.0)\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.10)\n","Collecting gorilla (from mlflow)\n","  Downloading https://files.pythonhosted.org/packages/e3/56/5a683944cbfc77e429c6f03c636ca50504a785f60ffae91ddd7f5f7bb520/gorilla-0.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: gunicorn in /usr/local/lib/python3.6/dist-packages (from mlflow) (19.9.0)\n","Collecting Mako (from alembic->mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/3c/8dcd6883d009f7cae0f3157fb53e9afb05a0d3d33b3db1268ec2e6f4a56b/Mako-1.1.0.tar.gz (463kB)\n","\u001b[K     |████████████████████████████████| 471kB 42.0MB/s \n","\u001b[?25hCollecting python-editor>=0.3 (from alembic->mlflow)\n","  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.5)\n","Collecting configparser>=0.3.5 (from databricks-cli>=0.8.7->mlflow)\n","  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2019.9.11)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (2.10.3)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.1.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (0.16.0)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->mlflow) (2018.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->mlflow) (41.2.0)\n","Collecting gitdb2>=2.0.0 (from gitpython>=2.1.0->mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 26.8MB/s \n","\u001b[?25hCollecting websocket-client>=0.32.0 (from docker>=4.0.0->mlflow)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n","\u001b[K     |████████████████████████████████| 204kB 35.0MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->mlflow) (1.1.1)\n","Collecting smmap2>=2.0.0 (from gitdb2>=2.0.0->gitpython>=2.1.0->mlflow)\n","  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n","Building wheels for collected packages: mlflow, alembic, databricks-cli, querystring-parser, simplejson, Mako\n","  Building wheel for mlflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mlflow: filename=mlflow-1.3.0-cp36-none-any.whl size=14540341 sha256=e5b20eb5476ba1d4745551b74f3ad2fd1090d7e13bc25470c5a8ad985605f0e4\n","  Stored in directory: /root/.cache/pip/wheels/f1/e0/1c/663c9b2bb00f32c235c98a43c39d81c2a25544a889a32649ea\n","  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for alembic: filename=alembic-1.2.1-py2.py3-none-any.whl size=144229 sha256=d2fb14c4387fb61372ea078afc4d7512fd357f3bab0ebb6e3f56d987106f1209\n","  Stored in directory: /root/.cache/pip/wheels/c6/b8/fd/1f16371156a8184172c4935cbbef6a345d57dd447e31a36633\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.9.0-cp36-none-any.whl size=83661 sha256=1f4c0b63fffabe445fbe81e2ff3368004de361083ec83de4cffab7365a631c24\n","  Stored in directory: /root/.cache/pip/wheels/e8/ce/cd/9d2214455ef53a4d9cdbca640dc27828a6c88cd5ef7d0c04de\n","  Building wheel for querystring-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for querystring-parser: filename=querystring_parser-1.2.4-cp36-none-any.whl size=7078 sha256=b0193730cbdab2fffda276f73b17a39d9c265dba3ff99081b05a1f14f716dc9c\n","  Stored in directory: /root/.cache/pip/wheels/1e/41/34/23ebf5d1089a9aed847951e0ee375426eb4ad0a7079d88d41e\n","  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for simplejson: filename=simplejson-3.16.0-cp36-cp36m-linux_x86_64.whl size=114017 sha256=d6350fdec0de2f5986f2a9ce216fe4ff45ddccd27104d026dd66e90b65b1ca27\n","  Stored in directory: /root/.cache/pip/wheels/5d/1a/1e/0350bb3df3e74215cd91325344cc86c2c691f5306eb4d22c77\n","  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Mako: filename=Mako-1.1.0-cp36-none-any.whl size=75363 sha256=a55cf6ef93dce32715f5eb53cd8d446c78ec0357a6b58767adb9c36f7dedc91a\n","  Stored in directory: /root/.cache/pip/wheels/98/32/7b/a291926643fc1d1e02593e0d9e247c5a866a366b8343b7aa27\n","Successfully built mlflow alembic databricks-cli querystring-parser simplejson Mako\n","Installing collected packages: Mako, python-editor, alembic, configparser, databricks-cli, smmap2, gitdb2, gitpython, querystring-parser, simplejson, websocket-client, docker, gorilla, mlflow\n","Successfully installed Mako-1.1.0 alembic-1.2.1 configparser-4.0.2 databricks-cli-0.9.0 docker-4.1.0 gitdb2-2.0.6 gitpython-3.0.3 gorilla-0.3.0 mlflow-1.3.0 python-editor-1.0.4 querystring-parser-1.2.4 simplejson-3.16.0 smmap2-2.0.5 websocket-client-0.56.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["configparser"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"-XNiuJPRjcRw","colab_type":"code","outputId":"60ebdb81-43df-4d47-8faa-3c18eda92911","executionInfo":{"status":"error","timestamp":1571592896261,"user_tz":180,"elapsed":1805,"user":{"displayName":"M. Natalia Moreno","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCyWYeeddN7Zfm-KW0sdvrHaN21NZ5GPdv1hFtrnA=s64","userId":"05126147472534650034"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["import mlflow\n","\n","mlflow.set_experiment('very_base_approach') # awesome_advanced_approach\n"," \n","with mlflow.start_run(nested=True):\n","    # Log model hiperparameters first\n","    mlflow.log_param('description_features_layer_size', DESCRIPTION_FEATURES_LAYER_SIZE)\n","    mlflow.log_param('hidden_layer_size', HIDDEN_LAYER_SIZE)\n","    mlflow.log_param('embedded_columns', embedded_columns)\n","    mlflow.log_param('one_hot_columns', one_hot_columns)\n","    # mlflow.log_param('numerical_columns', numerical_columns)  # Not using these yet\n","    \n","    # Train\n","    epochs = 10\n","    history = model.fit(train_dataset, epochs=epochs)\n","    \n","    # Evaluate\n","    loss, accuracy = model.evaluate(dev_dataset, verbose=0)\n","    print(\"\\n*** Validation loss: {} - accuracy: {}\".format(loss, accuracy))\n","    mlflow.log_metric('epochs', epochs)\n","    #mlflow.log_metric('train_loss', history.history[\"loss\"][-1])\n","    #mlflow.log_metric('train_accuracy', history.history[\"accuracy\"][-1])\n","    mlflow.log_metric('validation_loss', loss)\n","    mlflow.log_metric('validation_accuracy', accuracy)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["INFO: 'very_base_approach' does not exist. Creating a new experiment\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-f1e7027fec0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0mreset_dataset_after_each_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m       steps_per_epoch = training_utils.infer_steps_for_dataset(\n\u001b[0;32m--> 143\u001b[0;31m           model, inputs, steps_per_epoch, epochs=epochs, steps_name=steps_name)\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0minput_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36minfer_steps_for_dataset\u001b[0;34m(model, dataset, steps, epochs, steps_name)\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m   \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcardinality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFINITE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     raise ValueError('When passing an infinitely repeating dataset, you '\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3164\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexperimental_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5402\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5404\u001b[0;31m       raise ValueError(\"Cannot use the given session to evaluate tensor: \"\n\u001b[0m\u001b[1;32m   5405\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5406\u001b[0m                        \"graph.\")\n","\u001b[0;31mValueError\u001b[0m: Cannot use the given session to evaluate tensor: the tensor's graph is different from the session's graph."]}]},{"cell_type":"markdown","metadata":{"id":"qyvs-0fmjcRz","colab_type":"text"},"source":["## Evaluando el modelo sobre los datos de evaluación para la competencia\n","\n","Una vez que tenemos definido nuestro modelo, el último paso es ponerlo a prueba en los datos de evaluación para generar un archivo para enviar a la competencia Kaggle.\n","\n","Comenzamos cargando el conjunto de datos."]},{"cell_type":"code","metadata":{"id":"QZ76_0VpjcR0","colab_type":"code","outputId":"20dd6978-af88-44dc-f1ab-11208e17e2b0","colab":{}},"source":["test_dataset = pd.read_csv(os.path.join(DATA_DIRECTORY, 'test.csv'))\n","test_dataset.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Type</th>\n","      <th>Age</th>\n","      <th>Breed1</th>\n","      <th>Breed2</th>\n","      <th>Gender</th>\n","      <th>Color1</th>\n","      <th>Color2</th>\n","      <th>Color3</th>\n","      <th>MaturitySize</th>\n","      <th>FurLength</th>\n","      <th>Vaccinated</th>\n","      <th>Dewormed</th>\n","      <th>Sterilized</th>\n","      <th>Health</th>\n","      <th>Quantity</th>\n","      <th>Fee</th>\n","      <th>State</th>\n","      <th>Description</th>\n","      <th>PID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>265</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>41401</td>\n","      <td>I just found it alone yesterday near my apartm...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>307</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>41326</td>\n","      <td>Their pregnant mother was dumped by her irresp...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>307</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>41326</td>\n","      <td>Siu Pak just give birth on 13/6/10 to 6puppies...</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>12</td>\n","      <td>265</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>41326</td>\n","      <td>Very manja and gentle stray cat found, we woul...</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>264</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>41326</td>\n","      <td>Kali is a super playful kitten who is on the g...</td>\n","      <td>11</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n","0     2    1     265       0       1       1       2       0             2   \n","1     1    1     307       0       1       2       7       0             2   \n","2     1    0     307       0       2       1       2       7             2   \n","3     2   12     265       0       2       1       7       0             2   \n","4     2    3     264       0       2       1       2       5             3   \n","\n","   FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  State  \\\n","0          2           3         3           3       1         1    0  41401   \n","1          2           1         1           2       1         1    0  41326   \n","2          1           2         2           2       1         6    0  41326   \n","3          2           3         3           3       1         1    0  41326   \n","4          3           1         1           2       1         1   50  41326   \n","\n","                                         Description  PID  \n","0  I just found it alone yesterday near my apartm...    1  \n","1  Their pregnant mother was dumped by her irresp...    2  \n","2  Siu Pak just give birth on 13/6/10 to 6puppies...    7  \n","3  Very manja and gentle stray cat found, we woul...    9  \n","4  Kali is a super playful kitten who is on the g...   11  "]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"ydv5wRkNjcR3","colab_type":"text"},"source":["## Creamos el conjunto de datos para darle al modelo entrenado\n","\n","Tenemos que preprocesar los datos de evaluación de la misma manera que preprocesamos los de entrenamiento (para que sean compatibles con lo esperado por el modelo). Por suerte, es tan simple como hacer un par de modificaciones a lo ya hecho previamente. Lo único que tenemos que tener en cuenta es que ahora el conjunto de datos no generará una etiqueta."]},{"cell_type":"code","metadata":{"id":"rpYiuJPnjcR4","colab_type":"code","outputId":"ff9ba4db-c62c-4875-c8d2-eaaa12e4cdcb","colab":{}},"source":["# First tokenize the description\n","\n","test_dataset[\"TokenizedDescription\"] = test_dataset[\"Description\"]\\\n","    .fillna(value=\"\").apply(tokenize_description)\n","\n","# Generate the basic TF dataset\n","\n","tf_test_dataset = tf.data.Dataset.from_generator(\n","    lambda: dataset_generator(test_dataset, True),\n","    output_types=instance_types  # It should have the same instance types\n",")\n","\n","for data in tf_test_dataset.take(2):  # The dataset only returns a data instance now (no target)\n","    pprint(data)\n","    print()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{'Breed1': <tf.Tensor: id=3837, shape=(1,), dtype=int32, numpy=array([265], dtype=int32)>,\n"," 'description': <tf.Tensor: id=3838, shape=(13,), dtype=int32, numpy=\n","array([ 116,  429, 1371,  991,  189,    1, 7873, 1043,   62,  600,  728,\n","          5,    1], dtype=int32)>,\n"," 'direct_features': <tf.Tensor: id=3839, shape=(10,), dtype=float32, numpy=array([1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)>}\n","\n","{'Breed1': <tf.Tensor: id=3840, shape=(1,), dtype=int32, numpy=array([307], dtype=int32)>,\n"," 'description': <tf.Tensor: id=3841, shape=(47,), dtype=int32, numpy=\n","array([ 945,  154,  256, 2049,  105,  403,  991, 4678,  552,  545,    1,\n","        142,  134,  403,    1,  118,  210,   73,    1,  533,  387,   35,\n","        394,  272,   98,   62,    1,  464,  411,  151, 1401,   42,  253,\n","          1,  825,   35, 4660,  247, 4156, 1402, 1403,    1,   43,   52,\n","        599,   38,    1], dtype=int32)>,\n"," 'direct_features': <tf.Tensor: id=3842, shape=(10,), dtype=float32, numpy=array([1., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)>}\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9e8LSRlnjcR9","colab_type":"text"},"source":["## Padding batches\n","\n","Por último, y previo a probar el modelo sobre los datos de evaluación, generamos el conjunto de datos \"rellenado\". \n","\n","A diferencia de los datos de entrenamiento y validación, en este caso no permutamos las instancias, pues necesitamos saber a que `PID` pertenece cada una.\n","\n","Por otra parte, utilizamos los mismos valores de `padding_shapes` y `padding_values` para el primer componente (el de los datos), ignorando el valor del segundo componente (el de las etiquetas)."]},{"cell_type":"code","metadata":{"id":"ddVxmZBkjcR-","colab_type":"code","colab":{}},"source":["test_data = tf_test_dataset.padded_batch(\n","    BATCH_SIZE, \n","    padded_shapes=padding_shapes[0], \n","    padding_values=padding_values[0]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KgLw5RUmjcSB","colab_type":"text"},"source":["## Correr el modelo\n","\n","El último paso es correr el modelo sobre los datos de evaluación para conseguir las predicciones a enviar a la competencia."]},{"cell_type":"code","metadata":{"id":"u6b1e6HfjcSB","colab_type":"code","colab":{}},"source":["test_dataset[\"AdoptionSpeed\"] = model.predict(test_data).argmax(axis=1)\n","\n","test_dataset.to_csv(\"./submission.csv\", index=False, columns=[\"PID\", \"AdoptionSpeed\"])"],"execution_count":0,"outputs":[]}]}