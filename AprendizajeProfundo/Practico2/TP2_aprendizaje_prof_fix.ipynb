{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "TP_AP_Kaggle_TXT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr_e2op1jcQb",
        "colab_type": "text"
      },
      "source": [
        "# Práctico 2 - Redes en escalera avanzadas\n",
        "\n",
        "Este práctico es similar al práctico 1, pero agregará un paso extra que es el uso de redes en escalera avanzadas, ya sean Redes Convolucionales o Redes Recurrentes.\n",
        "\n",
        "Se les dará, como base, el mismo conjunto de datos de la competencia \"PetFinder\" que se trabajó para el práctico 1, con el agregado de, en este caso, utilizar la descripción como un feature extra y todo el procesamiento que ello requiere.\n",
        "\n",
        "Ahora bien, no es el único conjunto de datos que pueden trabajar. Si tienen un conjunto propio de datos que quieran utilizar y dicho conjunto se preste para el uso de alguna red en escalera avanzada (e.g. conjuntos que tengan imágenes o texto), son libres de hacerlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wbFkFbnEjcQe",
        "colab_type": "code",
        "outputId": "26ddd29e-59f7-4cd4-f55f-866804edfd23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "#import tensorflow as tf\n",
        "\n",
        "from IPython.display import SVG\n",
        "from gensim import corpora\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pprint import pprint\n",
        "\n",
        "nltk.download([\"punkt\", \"stopwords\"]);"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1VdxmIuvUlH",
        "colab_type": "code",
        "outputId": "71782e01-4f02-4844-f85c-a0827e99bc59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers, models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRmZNT9RjcQl",
        "colab_type": "text"
      },
      "source": [
        "## Carga de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KkzJBu5-WVz",
        "colab_type": "code",
        "outputId": "7162dba1-67a8-43ba-c0d8-68de86558e84",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ee20850-6cc8-44e4-8b60-152912d2d75d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8ee20850-6cc8-44e4-8b60-152912d2d75d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32FkLO-K-dK4",
        "colab_type": "code",
        "outputId": "e04c63af-338c-474f-a7f8-d83ee6ca3775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "import io\n",
        "\n",
        "dataset = pd.read_csv(io.BytesIO(os.path.join(uploaded['train.csv'])))\n",
        "\n",
        "target_col = 'AdoptionSpeed'\n",
        "nlabels = dataset[target_col].unique().shape[0]\n",
        "\n",
        "dataset.head(3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Age</th>\n",
              "      <th>Breed1</th>\n",
              "      <th>Breed2</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Color1</th>\n",
              "      <th>Color2</th>\n",
              "      <th>Color3</th>\n",
              "      <th>MaturitySize</th>\n",
              "      <th>FurLength</th>\n",
              "      <th>Vaccinated</th>\n",
              "      <th>Dewormed</th>\n",
              "      <th>Sterilized</th>\n",
              "      <th>Health</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Fee</th>\n",
              "      <th>State</th>\n",
              "      <th>Description</th>\n",
              "      <th>AdoptionSpeed</th>\n",
              "      <th>PID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>299</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>41326</td>\n",
              "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>307</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>150</td>\n",
              "      <td>41401</td>\n",
              "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>41326</td>\n",
              "      <td>This handsome yet cute boy is up for adoption....</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Type  Age  ...  AdoptionSpeed  PID\n",
              "0     2    3  ...              2    0\n",
              "1     1    4  ...              2    3\n",
              "2     1    1  ...              2    4\n",
              "\n",
              "[3 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJmpQD-WjcQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NO EJECUTAR: cargamos con la celda de arriba\n",
        "DATA_DIRECTORY = '../petfinder_dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ2lQ6ajjcQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NO EJECUTAR: cargamos con la celda de arriba\n",
        "dataset = pd.read_csv(os.path.join(DATA_DIRECTORY, 'train.csv'))\n",
        "\n",
        "target_col = 'AdoptionSpeed'\n",
        "nlabels = dataset[target_col].unique().shape[0]\n",
        "\n",
        "dataset.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-o38kmdjcQs",
        "colab_type": "text"
      },
      "source": [
        "## Preproceso del texto para agregarlo como feature (manejo de secuencias)\n",
        "\n",
        "A diferencia del práctico anterior, en este caso es necesario utilizar el texto como feature extra. Pueden luego agregarlo a una red recurrente o convolucional y concatenar su salida a los atributos \"escalares\" (como \"raza\" o \"género\").\n",
        "\n",
        "A continuación les mostraremos los pasos a seguir para ello. La descripción detallada de para que sirve cada paso se encuentra disponible en el [notebook 3](./3_cnns.ipynb).\n",
        "\n",
        "### Tokenización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b_psUctjcQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SW = set(stopwords.words(\"english\"))\n",
        "\n",
        "def tokenize_description(description):\n",
        "    return [w.lower() for w in word_tokenize(description, language=\"english\") if w.lower() not in SW]\n",
        "\n",
        "# Fill the null values with the empty string to avoid errors with NLTK tokenization\n",
        "dataset[\"TokenizedDescription\"] = dataset[\"Description\"].fillna(value=\"\").apply(tokenize_description)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvfONxa4jcQx",
        "colab_type": "text"
      },
      "source": [
        "#### Tamaño de las descripciones\n",
        "\n",
        "Un punto importante a tener en cuenta es que las descripciones tienen tamaño variable, y esto no es compatible con los algoritmos de aprendizaje automático. Por lo que hay que llevar las secuencias a un tamaño uniforme.\n",
        "\n",
        "Para definir dicho tamaño uniforme, es útil mirar qué tamaños mínimos, máximos y medios manejan las descripciones y a partir de esto establecer el tamaño máximo de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4nT5hw3jcQy",
        "colab_type": "code",
        "outputId": "93aac1eb-ea6c-44be-9b0e-479ab3837612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "pprint(dataset[\"TokenizedDescription\"].apply(len).describe())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    10582.000000\n",
            "mean        44.418541\n",
            "std         48.464623\n",
            "min          0.000000\n",
            "25%         16.000000\n",
            "50%         31.000000\n",
            "75%         55.000000\n",
            "max        803.000000\n",
            "Name: TokenizedDescription, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gU93yY4jcQ3",
        "colab_type": "text"
      },
      "source": [
        "Vemos que más del 75% de las secuencias tienen 55 palabras o menos. Esto es un buen punto de partida, así que podemos establecer el tamaño máximo de las secuencia en 55 palabras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqtQHueojcQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LEN = 55"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8S2SySvjcQ6",
        "colab_type": "text"
      },
      "source": [
        "## Vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6QzpphmjcQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = corpora.Dictionary(dataset[\"TokenizedDescription\"])\n",
        "vocabulary.filter_extremes(no_below=1, no_above=1.0, keep_n=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LstJBm6ojcQ-",
        "colab_type": "text"
      },
      "source": [
        "## Word Embeddings (GloVe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mftTOX-QDsGH",
        "colab_type": "code",
        "outputId": "96034733-72a6-45a7-ad18-153db5f28052",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "glove = files.upload()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6ed2915-8c7b-4099-b333-b581b82a6781\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d6ed2915-8c7b-4099-b333-b581b82a6781\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving glove.6B.100d.txt to glove.6B.100d.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ApdKoD3Dw7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "glove_file = io.BytesIO(os.path.join(glove['glove.6B.100d.txt']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME0tDuP-jcQ_",
        "colab_type": "code",
        "outputId": "87662b86-bd04-483a-97b3-9fa8980b11d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "#with open(\"./dataset/glove.6B.100d.txt\", \"r\") as fh:\n",
        "with open(\"glove.6B.100d.txt\", \"r\") as fh:\n",
        "    for line in fh:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        if word in vocabulary.token2id:  # Only use the embeddings of words in our vocabulary\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found {} word vectors.\".format(len(embeddings_index)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7897 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFAkr8e_jcRE",
        "colab_type": "text"
      },
      "source": [
        "## Creación de los datasets\n",
        "\n",
        "Similar al práctico anterior, tendremos datos que serán \"one-hot-encoded\", otros serán \"embeddings\" y otros serán numéricos.\n",
        "\n",
        "El caso particular del texto es que será tratado como una secuencia de embeddings, y dichos embeddings no serán entrenados en conjunto con la red, sino que serán tomados de un modelo \"pre-entrenado\". En este caso utilizamos GloVe, pero podríamos haber utilizado otro modelo (e.g. FastText)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pelssGejcRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# It's important to always use the same one-hot length\n",
        "one_hot_columns = {\n",
        "    one_hot_col: dataset[one_hot_col].max()\n",
        "    for one_hot_col in ['Gender', 'Color1', 'Color2'] #'Type', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health'\n",
        "}\n",
        "embedded_columns = {\n",
        "    embedded_col: dataset[embedded_col].max() + 1\n",
        "    for embedded_col in ['Breed1', 'Breed2'] #'State'\n",
        "}\n",
        "numeric_columns = ['Age', 'Quantity', 'Fee']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDXlReJxjcRI",
        "colab_type": "text"
      },
      "source": [
        "## Generador del conjunto de datos\n",
        "\n",
        "Dada la naturaleza de los datos de texto, y que estos representan una secuencia de datos (que se da luego a una red recurrente o convolucional), en este caso no crearemos los datasets de antemano, sino que los generaremos a medida que el algoritmo de entrenamiento los pida. \n",
        "\n",
        "En particular, es porque las secuencias de texto pueden no tener el mismo tamaño (las oraciones tienen diferente cantidad de palabras), pero para que los modelos de redes las acepten, necesitamos rellenarlas (*padding*) de manera que todas tengan el mismo tamaño.\n",
        "\n",
        "En este paso también vamos a truncar aquellas secuencias de descripciones con más de `MAX_SEQUENCE_LEN` palabras, de manera que al hacer uso de `padded_batch` no lance un error al encontrarse con secuencias de tamaño mayor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ykXHOnjcRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "77e2f1f4-eb17-4ec1-ec38-5fe7225d3291"
      },
      "source": [
        "def dataset_generator(ds, test_data=False):\n",
        "    for _, row in ds.iterrows():\n",
        "        instance = {}\n",
        "        \n",
        "        # One hot encoded features\n",
        "        instance[\"direct_features\"] = np.hstack([\n",
        "            tf.keras.utils.to_categorical(row[one_hot_col] - 1, max_value)\n",
        "            for one_hot_col, max_value in one_hot_columns.items()\n",
        "        ])\n",
        "\n",
        "        # Numeric features (should be normalized beforehand)\n",
        "        # TODO: Add numeric features for row\n",
        "        \n",
        "        # Embedded features\n",
        "        for embedded_col in embedded_columns:\n",
        "            instance[embedded_col] = [row[embedded_col]]\n",
        "\n",
        "        # DONE\n",
        "        for n_col in numeric_columns:\n",
        "            instance[n_col] = np.hstack(tf.keras.utils.normalize(ds[n_col].values)) \n",
        "        \n",
        "        # Document to indices for text data, truncated at MAX_SEQUENCE_LEN words\n",
        "        instance[\"description\"] = vocabulary.doc2idx(\n",
        "            row[\"TokenizedDescription\"],\n",
        "            unknown_word_index=len(vocabulary)\n",
        "        )[:MAX_SEQUENCE_LEN]\n",
        "        \n",
        "        # One hot encoded target for categorical crossentropy\n",
        "        if not test_data:\n",
        "            target = tf.keras.utils.to_categorical(row[target_col], nlabels)\n",
        "            yield instance, target\n",
        "        else:\n",
        "            yield instance\n",
        "\n",
        "# Set output types of the generator (for numeric types check the type is valid)\n",
        "instance_types = {\n",
        "    \"direct_features\": tf.float32,\n",
        "    \"description\": tf.int32\n",
        "}\n",
        "\n",
        "for embedded_col in embedded_columns:\n",
        "    instance_types[embedded_col] = tf.int32\n",
        "\n",
        "for n_col in numeric_columns:\n",
        "    instance_types[n_col] = tf.int32\n",
        "        \n",
        "tf_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: dataset_generator(dataset),\n",
        "    output_types=(instance_types, tf.int32)\n",
        ")\n",
        "\n",
        "for data, target in tf_dataset.take(2):\n",
        "    pprint(data)\n",
        "    pprint(target)\n",
        "    print()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Age': <tf.Tensor: shape=(10582,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>,\n",
            " 'Breed1': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([299], dtype=int32)>,\n",
            " 'Breed2': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>,\n",
            " 'Fee': <tf.Tensor: shape=(10582,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>,\n",
            " 'Quantity': <tf.Tensor: shape=(10582,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>,\n",
            " 'description': <tf.Tensor: shape=(42,), dtype=int32, numpy=\n",
            "array([23,  2, 20, 24,  4, 10,  1, 11, 26,  1, 27,  9,  6, 21,  3,  8, 15,\n",
            "       22, 33,  7, 13, 30,  1, 29, 18, 17,  1, 12, 31, 14,  5,  6, 16,  1,\n",
            "       19, 28, 25, 32, 23,  0,  5,  1], dtype=int32)>,\n",
            " 'direct_features': <tf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "      dtype=float32)>}\n",
            "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 1, 0, 0], dtype=int32)>\n",
            "\n",
            "{'Age': <tf.Tensor: shape=(10582,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>,\n",
            " 'Breed1': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([307], dtype=int32)>,\n",
            " 'Breed2': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>,\n",
            " 'Fee': <tf.Tensor: shape=(10582,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>,\n",
            " 'Quantity': <tf.Tensor: shape=(10582,), dtype=int32, numpy=array([0, 0, 0, ..., 0, 0, 0], dtype=int32)>,\n",
            " 'description': <tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
            "array([41, 42, 40, 35, 37, 35, 36, 35, 45, 50, 41, 44, 35, 46, 38, 48, 39,\n",
            "       47, 15, 43, 35, 49, 34, 34], dtype=int32)>,\n",
            " 'direct_features': <tf.Tensor: shape=(17,), dtype=float32, numpy=\n",
            "array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "      dtype=float32)>}\n",
            "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 1, 0, 0], dtype=int32)>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdYxXEsljcRM",
        "colab_type": "text"
      },
      "source": [
        "## Datos de entrenamiento y validación\n",
        "\n",
        "Ya generado el conjunto de datos base, tenemos que dividirlo en entrenamiento y validación. Además, como vamos a utilizar algunos datos que forman secuencias, los lotes (*batches*) de datos deben estar \"rellenados\" (*padded_batch*). \n",
        "\n",
        "Si bien rellenaremos \"todos\" los atributos, en la práctica el único que efectivamente se rellenará es el de *description* pues es el único con tamaños distintos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uubyx9wnjcRN",
        "colab_type": "code",
        "outputId": "22811147-ecc0-41bd-bb43-8362d465bb4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "TRAIN_SIZE = int(dataset.shape[0] * 0.8)\n",
        "DEV_SIZE = dataset.shape[0] - TRAIN_SIZE\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "shuffled_dataset = tf_dataset.shuffle(TRAIN_SIZE + DEV_SIZE, seed=42)\n",
        "\n",
        "#Agrego\n",
        "# Pad the datasets to the max value for all the \"non sequence\" features\n",
        "padding_shapes = (\n",
        "    {k: [-1] for k in [\"direct_features\"] + list(embedded_columns.keys()) + numeric_columns},\n",
        "    [-1]\n",
        ")\n",
        "\n",
        "# Pad to MAX_SEQUENCE_LEN for sequence features\n",
        "padding_shapes[0][\"description\"] = [MAX_SEQUENCE_LEN]\n",
        "\n",
        "# Pad values are irrelevant for non padded data\n",
        "padding_values = (\n",
        "    {k: 0 for k in list(embedded_columns.keys())},\n",
        "    0\n",
        ")\n",
        "\n",
        "# Padding value for direct features should be a float\n",
        "padding_values[0][\"direct_features\"] = np.float32(0)\n",
        "\n",
        "# Padding value for sequential features is the vocabulary length + 1\n",
        "padding_values[0][\"description\"] = len(vocabulary) + 1\n",
        "\n",
        "#Agrego\n",
        "padding_values[0][\"Age\"] = np.int32(0)\n",
        "padding_values[0][\"Fee\"] = np.int32(0)\n",
        "padding_values[0][\"Quantity\"] = np.int32(0)\n",
        "\n",
        "print(padding_shapes)\n",
        "print(padding_values)\n",
        "train_dataset = shuffled_dataset.skip(DEV_SIZE)\\\n",
        "    .padded_batch(BATCH_SIZE, padded_shapes=padding_shapes, padding_values=padding_values)\n",
        "\n",
        "dev_dataset = shuffled_dataset.take(DEV_SIZE)\\\n",
        "    .padded_batch(BATCH_SIZE, padded_shapes=padding_shapes, padding_values=padding_values)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'direct_features': [-1], 'Breed1': [-1], 'Breed2': [-1], 'Age': [-1], 'Quantity': [-1], 'Fee': [-1], 'description': [55]}, [-1])\n",
            "({'Breed1': 0, 'Breed2': 0, 'direct_features': 0.0, 'description': 10001, 'Age': 0, 'Fee': 0, 'Quantity': 0}, 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS1IyRBpjcRQ",
        "colab_type": "text"
      },
      "source": [
        "## Construyendo el modelo\n",
        "\n",
        "Al modelo anterior tenemos que agregarle la capa que maneje los embeddings de las palabras, e inicializarla de manera acorde, podemos guiarnos por lo visto en el [notebook 3](./3_cnns.ipynb) para hacer esto.\n",
        "\n",
        "### Matriz de embeddings de palabras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q-IncHyjcRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDINGS_DIM = 100  # Given by the model (in this case glove.6B.100d)\n",
        "\n",
        "embedding_matrix = np.zeros((len(vocabulary) + 2, 100))\n",
        "\n",
        "for widx, word in vocabulary.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[widx] = embedding_vector\n",
        "    else:\n",
        "        # Random normal initialization for words without embeddings\n",
        "        embedding_matrix[widx] = np.random.normal(size=(100,))  \n",
        "\n",
        "# Random normal initialization for unknown words\n",
        "embedding_matrix[len(vocabulary)] = np.random.normal(size=(100,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myVabjLYjcRV",
        "colab_type": "text"
      },
      "source": [
        "### Definiendo los inputs del modelo\n",
        "\n",
        "Definamos los inputs del modelo, con el agregado de la capa de embeddings de palabras inicializada en `embedding_matrix`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdvtRtvrjcRW",
        "colab_type": "code",
        "outputId": "72901f5a-3c0b-4498-b151-5684bb3726d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Add one input and one embedding for each embedded column\n",
        "embedding_layers = []\n",
        "numeric_layer = []\n",
        "inputs = []\n",
        "for embedded_col, max_value in embedded_columns.items():\n",
        "    input_layer = tf.keras.layers.Input(shape=(1,), name=embedded_col)\n",
        "    inputs.append(input_layer)\n",
        "    # Define the embedding layer\n",
        "    embedding_size = int(max_value / 4)\n",
        "    embedding_layers.append(\n",
        "        tf.squeeze(\n",
        "            tf.keras.layers.Embedding(\n",
        "                input_dim=max_value, \n",
        "                output_dim=embedding_size\n",
        "            )(input_layer), \n",
        "            axis=-2\n",
        "        )\n",
        "    )\n",
        "    print('Adding embedding of size {} for layer {}'.format(embedding_size, embedded_col))\n",
        "\n",
        "# Add the direct features already calculated\n",
        "direct_features_input = tf.keras.layers.Input(\n",
        "    shape=(sum(one_hot_columns.values()),), \n",
        "    name='direct_features'\n",
        ")\n",
        "inputs.append(direct_features_input)\n",
        "\n",
        "# DONE: Add Numerics\n",
        "for col in numeric_columns:\n",
        "    input_num_layer = tf.keras.layers.Input(shape=(1,), name=col)\n",
        "    inputs.append(input_num_layer)\n",
        "    numeric_layer.append(input_num_layer)\n",
        "\n",
        "# Word embedding layer\n",
        "description_input = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LEN,), name=\"description\")\n",
        "inputs.append(description_input)\n",
        "\n",
        "word_embeddings_layer = tf.keras.layers.Embedding(\n",
        "    embedding_matrix.shape[0],\n",
        "    EMBEDDINGS_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_SEQUENCE_LEN,\n",
        "    trainable=False,\n",
        "    name=\"word_embedding\"\n",
        ")(description_input)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adding embedding of size 77 for layer Breed1\n",
            "Adding embedding of size 77 for layer Breed2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL3BBNDwjcRZ",
        "colab_type": "text"
      },
      "source": [
        "### Definiendo la red que trabajará con el texto\n",
        "\n",
        "Antes de generar el *feature map* final entre los inputs y las clases, tenemos que generar el *feature map* de las secuencias de texto. \n",
        "\n",
        "Para ello pueden utilizar una red neuronal recurrente o convolucional.\n",
        "\n",
        "Pueden pensar dicha red como un submodelo del modelo general que se encarga de generar los atributos que representan la descripción de la mascota (recordemos que las redes se utilizan para hacer aprendizaje de representaciones).\n",
        "\n",
        "La red puede ser tan compleja como ustedes lo consideren pertinente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyDzENoQjcRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "77940d06-f7fa-4d0a-eff1-1219cd57541b"
      },
      "source": [
        "## TODO: Create a NN (CNN or RNN) for the description input (replace the next)\n",
        "#DESCRIPTION_FEATURES_LAYER_SIZE = 512\n",
        "\n",
        "#description_features = tf.keras.layers.Flatten()(word_embeddings_layer)  # This is a simple concatenation\n",
        "#description_features = tf.keras.layers.Dense(\n",
        "#    units=DESCRIPTION_FEATURES_LAYER_SIZE, \n",
        "#    activation=\"relu\", \n",
        "#    name=\"description_features\")(description_features)\n",
        "\n",
        "WORDS_SIZE = [2, 4, 8, 16]  # Fibonacci  :)\n",
        "FILTER = 50\n",
        "\n",
        "sequence_input = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LEN,), dtype='int64', name=\"input\")\n",
        "\n",
        "# The embedding layer is initialized with our embedding_matrix\n",
        "embeddings_layer = tf.keras.layers.Embedding(\n",
        "    embedding_matrix.shape[0],\n",
        "    EMBEDDINGS_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_SEQUENCE_LEN,\n",
        "    trainable=False,\n",
        "    name=\"word_embedding\"\n",
        ")\n",
        "embedded_sequences = embeddings_layer(sequence_input)\n",
        "\n",
        "# Convultional layer\n",
        "conv_layers = []\n",
        "for filter_width in WORDS_SIZE:\n",
        "    layer = tf.keras.layers.Conv1D(\n",
        "        FILTER,\n",
        "        filter_width,\n",
        "        activation=\"relu\",\n",
        "        name=\"conv_{}_words\".format(filter_width)\n",
        "    )(embedded_sequences)\n",
        "    layer = tf.keras.layers.GlobalMaxPooling1D(name=\"max_pool_{}_words\".format(filter_width))(layer)\n",
        "    conv_layers.append(layer)\n",
        "\n",
        "convolved_features = tf.keras.layers.Concatenate(name=\"convolved_features\")(conv_layers)\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(convolved_features)\n",
        "model = tf.keras.models.Model(inputs=[sequence_input], outputs=[output], name=\"Red convolucional para texto\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"nadam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "DESCRIPTION_FEATURES_LAYER_SIZE = 512\n",
        "\n",
        "description_features = tf.keras.layers.Flatten()(word_embeddings_layer)  # This is a simple concatenation\n",
        "description_features = tf.keras.layers.Dense(units=DESCRIPTION_FEATURES_LAYER_SIZE, \n",
        "                                             activation=\"relu\", name=\"description_features\")(description_features)\n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Red convolucional para texto\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_embedding (Embedding)      (None, 55, 100)      1000200     input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv_2_words (Conv1D)           (None, 54, 50)       10050       word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_4_words (Conv1D)           (None, 52, 50)       20050       word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_8_words (Conv1D)           (None, 48, 50)       40050       word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_16_words (Conv1D)          (None, 40, 50)       80050       word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_2_words (GlobalMaxPool (None, 50)           0           conv_2_words[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_4_words (GlobalMaxPool (None, 50)           0           conv_4_words[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_8_words (GlobalMaxPool (None, 50)           0           conv_8_words[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pool_16_words (GlobalMaxPoo (None, 50)           0           conv_16_words[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "convolved_features (Concatenate (None, 200)          0           max_pool_2_words[0][0]           \n",
            "                                                                 max_pool_4_words[0][0]           \n",
            "                                                                 max_pool_8_words[0][0]           \n",
            "                                                                 max_pool_16_words[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            201         convolved_features[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 1,150,601\n",
            "Trainable params: 150,401\n",
            "Non-trainable params: 1,000,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLfz3muqjcRd",
        "colab_type": "text"
      },
      "source": [
        "### Definiendo el *feature map* final de la red\n",
        "\n",
        "Ahora que tenemos nuestra representación de las descripciones, pasamos a combinarlo con los demás features en la última parte de nuestra red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av9xWay2jcRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_LAYER_SIZE = 512\n",
        "DROPOUT = 0.25\n",
        "\n",
        "feature_map = tf.keras.layers.Concatenate(name=\"feature_map\")(\n",
        "    embedding_layers + [description_features, direct_features_input] # + numeric_layer  #(se me rompe con las col numericas que tenia de anterior practico pero dejo las de word embedding)   \n",
        ")\n",
        "\n",
        "hidden_layer_lv1 = tf.keras.layers.Dense(HIDDEN_LAYER_SIZE, activation=\"relu\")(feature_map)\n",
        "drop1 = layers.Dropout(DROPOUT)(hidden_layer_lv1)\n",
        "hidden_layer_lv2 = tf.keras.layers.Dense(HIDDEN_LAYER_SIZE / 2, activation=\"relu\")(drop1)\n",
        "drop2 = layers.Dropout(DROPOUT)(hidden_layer_lv2)\n",
        "hidden_layer_lv3 = tf.keras.layers.Dense(HIDDEN_LAYER_SIZE / 4, activation=\"relu\")(drop2)\n",
        "output_layer = tf.keras.layers.Dense(nlabels, activation=\"softmax\", name=\"output\")(hidden_layer_lv3)  # Concatene layers output -> input\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=[output_layer], name=\"amazing_model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znr-tvvrjcRh",
        "colab_type": "text"
      },
      "source": [
        "### Compilando y visualizando el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvCJu49njcRj",
        "colab_type": "code",
        "outputId": "6a5d016b-657d-4b35-9097-1fd7eb63c1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='nadam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"amazing_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "description (InputLayer)        [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Breed2 (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_embedding (Embedding)      (None, 55, 100)      1000200     description[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 77)        23716       Breed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 5500)         0           word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_1 (TensorFl [(None, 77)]         0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "description_features (Dense)    (None, 512)          2816512     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "direct_features (InputLayer)    [(None, 17)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Age (InputLayer)                [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Quantity (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Fee (InputLayer)                [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_map (Concatenate)       (None, 686)          0           tf_op_layer_Squeeze[0][0]        \n",
            "                                                                 tf_op_layer_Squeeze_1[0][0]      \n",
            "                                                                 description_features[0][0]       \n",
            "                                                                 direct_features[0][0]            \n",
            "                                                                 Age[0][0]                        \n",
            "                                                                 Quantity[0][0]                   \n",
            "                                                                 Fee[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_42 (Dense)                (None, 512)          351744      feature_map[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 512)          0           dense_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 256)          131328      dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 256)          0           dense_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 128)          32896       dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 5)            645         dense_44[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,380,757\n",
            "Trainable params: 3,380,557\n",
            "Non-trainable params: 1,000,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4_mAl1-jcRp",
        "colab_type": "code",
        "outputId": "2eb747e0-3e4a-4a86-cab3-25718d2ddb70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        }
      },
      "source": [
        "SVG(tf.keras.utils.model_to_dot(model, dpi=60).create(prog='dot', format='svg'))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"646pt\" viewBox=\"0.00 0.00 1373.00 775.00\" width=\"1144pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 771)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-771 1369,-771 1369,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140708326438616 -->\n<g class=\"node\" id=\"node1\">\n<title>140708326438616</title>\n<polygon fill=\"none\" points=\"21.5,-730.5 21.5,-766.5 172.5,-766.5 172.5,-730.5 21.5,-730.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-744.8\">description: InputLayer</text>\n</g>\n<!-- 140708329031160 -->\n<g class=\"node\" id=\"node4\">\n<title>140708329031160</title>\n<polygon fill=\"none\" points=\"0,-657.5 0,-693.5 194,-693.5 194,-657.5 0,-657.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-671.8\">word_embedding: Embedding</text>\n</g>\n<!-- 140708326438616&#45;&gt;140708329031160 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140708326438616-&gt;140708329031160</title>\n<path d=\"M97,-730.4551C97,-722.3828 97,-712.6764 97,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"100.5001,-703.5903 97,-693.5904 93.5001,-703.5904 100.5001,-703.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708337353056 -->\n<g class=\"node\" id=\"node2\">\n<title>140708337353056</title>\n<polygon fill=\"none\" points=\"269.5,-657.5 269.5,-693.5 398.5,-693.5 398.5,-657.5 269.5,-657.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334\" y=\"-671.8\">Breed1: InputLayer</text>\n</g>\n<!-- 140708332993000 -->\n<g class=\"node\" id=\"node5\">\n<title>140708332993000</title>\n<polygon fill=\"none\" points=\"256,-584.5 256,-620.5 412,-620.5 412,-584.5 256,-584.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334\" y=\"-598.8\">embedding: Embedding</text>\n</g>\n<!-- 140708337353056&#45;&gt;140708332993000 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140708337353056-&gt;140708332993000</title>\n<path d=\"M334,-657.4551C334,-649.3828 334,-639.6764 334,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"337.5001,-630.5903 334,-620.5904 330.5001,-630.5904 337.5001,-630.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708332993504 -->\n<g class=\"node\" id=\"node3\">\n<title>140708332993504</title>\n<polygon fill=\"none\" points=\"560.5,-657.5 560.5,-693.5 689.5,-693.5 689.5,-657.5 560.5,-657.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625\" y=\"-671.8\">Breed2: InputLayer</text>\n</g>\n<!-- 140708331618032 -->\n<g class=\"node\" id=\"node6\">\n<title>140708331618032</title>\n<polygon fill=\"none\" points=\"539.5,-584.5 539.5,-620.5 710.5,-620.5 710.5,-584.5 539.5,-584.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625\" y=\"-598.8\">embedding_1: Embedding</text>\n</g>\n<!-- 140708332993504&#45;&gt;140708331618032 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140708332993504-&gt;140708331618032</title>\n<path d=\"M625,-657.4551C625,-649.3828 625,-639.6764 625,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"628.5001,-630.5903 625,-620.5904 621.5001,-630.5904 628.5001,-630.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708334770440 -->\n<g class=\"node\" id=\"node7\">\n<title>140708334770440</title>\n<polygon fill=\"none\" points=\"48,-584.5 48,-620.5 146,-620.5 146,-584.5 48,-584.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-598.8\">flatten: Flatten</text>\n</g>\n<!-- 140708329031160&#45;&gt;140708334770440 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140708329031160-&gt;140708334770440</title>\n<path d=\"M97,-657.4551C97,-649.3828 97,-639.6764 97,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"100.5001,-630.5903 97,-620.5904 93.5001,-630.5904 100.5001,-630.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708320754768 -->\n<g class=\"node\" id=\"node8\">\n<title>140708320754768</title>\n<polygon fill=\"none\" points=\"201.5,-511.5 201.5,-547.5 466.5,-547.5 466.5,-511.5 201.5,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"334\" y=\"-525.8\">tf_op_layer_Squeeze: TensorFlowOpLayer</text>\n</g>\n<!-- 140708332993000&#45;&gt;140708320754768 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140708332993000-&gt;140708320754768</title>\n<path d=\"M334,-584.4551C334,-576.3828 334,-566.6764 334,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"337.5001,-557.5903 334,-547.5904 330.5001,-557.5904 337.5001,-557.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708320753480 -->\n<g class=\"node\" id=\"node9\">\n<title>140708320753480</title>\n<polygon fill=\"none\" points=\"485,-511.5 485,-547.5 765,-547.5 765,-511.5 485,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625\" y=\"-525.8\">tf_op_layer_Squeeze_1: TensorFlowOpLayer</text>\n</g>\n<!-- 140708331618032&#45;&gt;140708320753480 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140708331618032-&gt;140708320753480</title>\n<path d=\"M625,-584.4551C625,-576.3828 625,-566.6764 625,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"628.5001,-557.5903 625,-547.5904 621.5001,-557.5904 628.5001,-557.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708325414448 -->\n<g class=\"node\" id=\"node13\">\n<title>140708325414448</title>\n<polygon fill=\"none\" points=\"10.5,-511.5 10.5,-547.5 183.5,-547.5 183.5,-511.5 10.5,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-525.8\">description_features: Dense</text>\n</g>\n<!-- 140708334770440&#45;&gt;140708325414448 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140708334770440-&gt;140708325414448</title>\n<path d=\"M97,-584.4551C97,-576.3828 97,-566.6764 97,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"100.5001,-557.5903 97,-547.5904 93.5001,-557.5904 100.5001,-557.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708341876608 -->\n<g class=\"node\" id=\"node15\">\n<title>140708341876608</title>\n<polygon fill=\"none\" points=\"757,-438.5 757,-474.5 921,-474.5 921,-438.5 757,-438.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839\" y=\"-452.8\">feature_map: Concatenate</text>\n</g>\n<!-- 140708320754768&#45;&gt;140708341876608 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140708320754768-&gt;140708341876608</title>\n<path d=\"M458.8315,-511.4551C547.9033,-498.5793 665.7388,-481.5457 746.4742,-469.875\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"747.2283,-473.3025 756.6246,-468.4077 746.2267,-466.3745 747.2283,-473.3025\" stroke=\"#000000\"/>\n</g>\n<!-- 140708320753480&#45;&gt;140708341876608 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140708320753480-&gt;140708341876608</title>\n<path d=\"M677.8989,-511.4551C707.7358,-501.277 745.1891,-488.5009 776.4726,-477.8294\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"777.6335,-481.1315 785.968,-474.5904 775.3735,-474.5064 777.6335,-481.1315\" stroke=\"#000000\"/>\n</g>\n<!-- 140708326437104 -->\n<g class=\"node\" id=\"node10\">\n<title>140708326437104</title>\n<polygon fill=\"none\" points=\"783,-511.5 783,-547.5 895,-547.5 895,-511.5 783,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839\" y=\"-525.8\">Age: InputLayer</text>\n</g>\n<!-- 140708326437104&#45;&gt;140708341876608 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140708326437104-&gt;140708341876608</title>\n<path d=\"M839,-511.4551C839,-503.3828 839,-493.6764 839,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"842.5001,-484.5903 839,-474.5904 835.5001,-484.5904 842.5001,-484.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708329032224 -->\n<g class=\"node\" id=\"node11\">\n<title>140708329032224</title>\n<polygon fill=\"none\" points=\"913,-511.5 913,-547.5 1051,-547.5 1051,-511.5 913,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"982\" y=\"-525.8\">Quantity: InputLayer</text>\n</g>\n<!-- 140708329032224&#45;&gt;140708341876608 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140708329032224-&gt;140708341876608</title>\n<path d=\"M946.6517,-511.4551C927.5733,-501.7157 903.8348,-489.5975 883.5077,-479.2207\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"884.9353,-476.0198 874.4373,-474.5904 881.7525,-482.2544 884.9353,-476.0198\" stroke=\"#000000\"/>\n</g>\n<!-- 140708329030376 -->\n<g class=\"node\" id=\"node12\">\n<title>140708329030376</title>\n<polygon fill=\"none\" points=\"1069,-511.5 1069,-547.5 1177,-547.5 1177,-511.5 1069,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1123\" y=\"-525.8\">Fee: InputLayer</text>\n</g>\n<!-- 140708329030376&#45;&gt;140708341876608 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140708329030376-&gt;140708341876608</title>\n<path d=\"M1068.7465,-513.4045C1065.7914,-512.579 1062.8614,-511.7725 1060,-511 1015.8552,-499.0814 966.4672,-486.8029 925.5943,-476.9247\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"926.2072,-473.4723 915.6655,-474.5318 924.5671,-480.2774 926.2072,-473.4723\" stroke=\"#000000\"/>\n</g>\n<!-- 140708325414448&#45;&gt;140708341876608 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140708325414448-&gt;140708341876608</title>\n<path d=\"M183.6565,-512.2234C186.4672,-511.7914 189.254,-511.3819 192,-511 388.5602,-483.6645 620.7572,-468.1515 746.6173,-461.1282\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"747.185,-464.6022 756.9767,-460.5559 746.7988,-457.6129 747.185,-464.6022\" stroke=\"#000000\"/>\n</g>\n<!-- 140708332993224 -->\n<g class=\"node\" id=\"node14\">\n<title>140708332993224</title>\n<polygon fill=\"none\" points=\"1195,-511.5 1195,-547.5 1365,-547.5 1365,-511.5 1195,-511.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1280\" y=\"-525.8\">direct_features: InputLayer</text>\n</g>\n<!-- 140708332993224&#45;&gt;140708341876608 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140708332993224-&gt;140708341876608</title>\n<path d=\"M1194.9731,-512.6135C1191.9463,-512.061 1188.9481,-511.5214 1186,-511 1099.8617,-495.765 1001.307,-480.4918 931.2956,-470.0066\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"931.5855,-466.5111 921.178,-468.4949 930.551,-473.4343 931.5855,-466.5111\" stroke=\"#000000\"/>\n</g>\n<!-- 140708332616336 -->\n<g class=\"node\" id=\"node16\">\n<title>140708332616336</title>\n<polygon fill=\"none\" points=\"782,-365.5 782,-401.5 896,-401.5 896,-365.5 782,-365.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839\" y=\"-379.8\">dense_33: Dense</text>\n</g>\n<!-- 140708341876608&#45;&gt;140708332616336 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140708341876608-&gt;140708332616336</title>\n<path d=\"M839,-438.4551C839,-430.3828 839,-420.6764 839,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"842.5001,-411.5903 839,-401.5904 835.5001,-411.5904 842.5001,-411.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708329046200 -->\n<g class=\"node\" id=\"node17\">\n<title>140708329046200</title>\n<polygon fill=\"none\" points=\"768.5,-292.5 768.5,-328.5 909.5,-328.5 909.5,-292.5 768.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839\" y=\"-306.8\">dropout_22: Dropout</text>\n</g>\n<!-- 140708332616336&#45;&gt;140708329046200 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140708332616336-&gt;140708329046200</title>\n<path d=\"M839,-365.4551C839,-357.3828 839,-347.6764 839,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"842.5001,-338.5903 839,-328.5904 835.5001,-338.5904 842.5001,-338.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708333300368 -->\n<g class=\"node\" id=\"node18\">\n<title>140708333300368</title>\n<polygon fill=\"none\" points=\"782,-219.5 782,-255.5 896,-255.5 896,-219.5 782,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839\" y=\"-233.8\">dense_34: Dense</text>\n</g>\n<!-- 140708329046200&#45;&gt;140708333300368 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140708329046200-&gt;140708333300368</title>\n<path d=\"M839,-292.4551C839,-284.3828 839,-274.6764 839,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"842.5001,-265.5903 839,-255.5904 835.5001,-265.5904 842.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708337564584 -->\n<g class=\"node\" id=\"node19\">\n<title>140708337564584</title>\n<polygon fill=\"none\" points=\"768.5,-146.5 768.5,-182.5 909.5,-182.5 909.5,-146.5 768.5,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839\" y=\"-160.8\">dropout_23: Dropout</text>\n</g>\n<!-- 140708333300368&#45;&gt;140708337564584 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140708333300368-&gt;140708337564584</title>\n<path d=\"M839,-219.4551C839,-211.3828 839,-201.6764 839,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"842.5001,-192.5903 839,-182.5904 835.5001,-192.5904 842.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708337690048 -->\n<g class=\"node\" id=\"node20\">\n<title>140708337690048</title>\n<polygon fill=\"none\" points=\"782,-73.5 782,-109.5 896,-109.5 896,-73.5 782,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839\" y=\"-87.8\">dense_35: Dense</text>\n</g>\n<!-- 140708337564584&#45;&gt;140708337690048 -->\n<g class=\"edge\" id=\"edge19\">\n<title>140708337564584-&gt;140708337690048</title>\n<path d=\"M839,-146.4551C839,-138.3828 839,-128.6764 839,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"842.5001,-119.5903 839,-109.5904 835.5001,-119.5904 842.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140707259908224 -->\n<g class=\"node\" id=\"node21\">\n<title>140707259908224</title>\n<polygon fill=\"none\" points=\"790.5,-.5 790.5,-36.5 887.5,-36.5 887.5,-.5 790.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"839\" y=\"-14.8\">output: Dense</text>\n</g>\n<!-- 140708337690048&#45;&gt;140707259908224 -->\n<g class=\"edge\" id=\"edge20\">\n<title>140708337690048-&gt;140707259908224</title>\n<path d=\"M839,-73.4551C839,-65.3828 839,-55.6764 839,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"842.5001,-46.5903 839,-36.5904 835.5001,-46.5904 842.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XB8t6yDjcRv",
        "colab_type": "text"
      },
      "source": [
        "## Entrenando el modelo\n",
        "\n",
        "Para entrenar el modelo es igual al caso anterior, ya generados el conjunto de datos correspondiente. Lo entrenamos con ayuda de `mlflow`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI5qe7_ZjhU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install mlflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHDhlK5opUgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "e8d59754-6f3d-475b-f551-7cd2092401e8"
      },
      "source": [
        "#RuntimeError: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='nadam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"amazing_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "description (InputLayer)        [(None, 55)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Breed2 (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "word_embedding (Embedding)      (None, 55, 100)      1000200     description[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 77)        23716       Breed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 5500)         0           word_embedding[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_1 (TensorFl [(None, 77)]         0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "description_features (Dense)    (None, 512)          2816512     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "direct_features (InputLayer)    [(None, 17)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "feature_map (Concatenate)       (None, 683)          0           tf_op_layer_Squeeze[0][0]        \n",
            "                                                                 tf_op_layer_Squeeze_1[0][0]      \n",
            "                                                                 description_features[0][0]       \n",
            "                                                                 direct_features[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 512)          350208      feature_map[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 512)          0           dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 256)          131328      dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 256)          0           dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 128)          32896       dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "Age (InputLayer)                [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Quantity (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Fee (InputLayer)                [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 5)            645         dense_47[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,379,221\n",
            "Trainable params: 3,379,021\n",
            "Non-trainable params: 1,000,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XNiuJPRjcRw",
        "colab_type": "code",
        "outputId": "1647c85e-9e72-424d-fca5-890258a311af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow.set_experiment('very_base_approach') # awesome_advanced_approach\n",
        " \n",
        "with mlflow.start_run(nested=True):\n",
        "    # Log model hiperparameters first\n",
        "    mlflow.log_param('description_features_layer_size', DESCRIPTION_FEATURES_LAYER_SIZE)\n",
        "    mlflow.log_param('hidden_layer_size', HIDDEN_LAYER_SIZE)\n",
        "    mlflow.log_param('embedded_columns', embedded_columns)\n",
        "    mlflow.log_param('one_hot_columns', one_hot_columns)\n",
        "    mlflow.log_param('numeric_columns', numeric_columns)  # Not using these yet\n",
        "    \n",
        "    # Train\n",
        "    epochs = 10\n",
        "    history = model.fit(train_dataset, epochs=epochs)\n",
        "    \n",
        "    # Evaluate\n",
        "    loss, accuracy = model.evaluate(dev_dataset, verbose=0)\n",
        "    print(\"\\n*** Validation loss: {} - accuracy: {}\".format(loss, accuracy))\n",
        "    mlflow.log_metric('epochs', epochs)\n",
        "    #mlflow.log_metric('train_loss', history.history[\"loss\"][-1])\n",
        "    #mlflow.log_metric('train_accuracy', history.history[\"accuracy\"][-1])\n",
        "    mlflow.log_metric('validation_loss', loss)\n",
        "    mlflow.log_metric('validation_accuracy', accuracy)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "67/67 [==============================] - 12s 185ms/step - loss: 0.5868 - accuracy: 0.7875\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 12s 176ms/step - loss: 0.1489 - accuracy: 0.9530\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 11s 167ms/step - loss: 0.1255 - accuracy: 0.9576\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 11s 168ms/step - loss: 0.1200 - accuracy: 0.9603\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 12s 173ms/step - loss: 0.0894 - accuracy: 0.9682\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 12s 175ms/step - loss: 0.1129 - accuracy: 0.9620\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 11s 170ms/step - loss: 0.0873 - accuracy: 0.9647\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 11s 171ms/step - loss: 0.0896 - accuracy: 0.9652\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 11s 170ms/step - loss: 0.1432 - accuracy: 0.9533\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 11s 169ms/step - loss: 0.0842 - accuracy: 0.9690\n",
            "\n",
            "*** Validation loss: 0.05818984898574212 - accuracy: 0.9787434935569763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz7guWTN-J2L",
        "colab_type": "text"
      },
      "source": [
        "Comentarios:\n",
        "\n",
        "Claramente el modelo realiza Overfiting ya que se llego a un valor de 0.40 con una red neuronal muy simple en el concurso anterior con el mismo dataset. En este caso tenemos valores que superan por lejos el baseline anterior.\n",
        "\n",
        "Si utilizamos menos layers en el modelo o mayor dropout los resultados son mas reales, aunque podemos animarnos a decir, que el costo de agregar la descripcion no vale a las mejoras en los resultados obtenidos.\n",
        "\n",
        "Al menos se consiguio aplicar una red convulsional para tratar el campo description. Por alguna razon que no determinamos, al ingresar los 3 campos numericos se rompe el modelo al momento de entrenarlo, ya que la matriz no coincide con las dimensiones esperadas, aunque se comparo con el ejercicio anterior no se identifica el lugar donde se produce el error en el codigo. Se agradece feedback al respecto.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}